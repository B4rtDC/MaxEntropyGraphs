var documenterSearchIndex = {"docs":
[{"location":"models/DBCM/#DCBM","page":"DBCM","title":"DCBM","text":"","category":"section"},{"location":"models/DBCM/#Model-description","page":"DBCM","title":"Model description","text":"","category":"section"},{"location":"models/DBCM/","page":"DBCM","title":"DBCM","text":"The Directed Binary Configuration Model (DBCM) is a maximum-entropy null model for undirected networks. It is based on the idea of fixing the in- and outdegree sequence of the network, i.e., the number of incoming and outgoing edges incident to each node, and then randomly rewiring the edges while preserving the degree sequence. The model assumes that the edges are unweighted and that the network is simple, i.e., it has no self-loops or multiple edges between the same pair of nodes [1,2]. ","category":"page"},{"location":"models/DBCM/","page":"DBCM","title":"DBCM","text":"We define the parameter vector as theta = alpha  beta, where alpha and beta denote the parameters associated with the out- and indegree respectively.","category":"page"},{"location":"models/DBCM/","page":"DBCM","title":"DBCM","text":"Description Formula\nConstraints forall i begincases k_i out(A^*) = sum_j=1^N a^*_ij  k_i in(A^*) = sum_j=1^N a^*_ji endcases\nHamiltonian H(A Theta) = H(A alpha beta) = sum_i=1^N alpha_i k_iout(A) +  beta_i k_iin(A)\nFactorized graph probability P(A  Theta) = prod_i=1^Nprod_j=1 j ne i^N p_ij^a_ij (1 - p_ij)^1-a_ij\nlangle a_ij rangle p_ij = frace^-alpha_i - beta_j1+e^-alpha_i - beta_j\nLog-likelihood mathcalL(Theta) = -sum_i=1^N left alpha_i k_iout(A^*) +  beta_i k_iin(A^*) right - sum_i=1^N sum_j=1 jne i^N ln left( 1+e^-alpha_i - beta_j right)\nlangle a_ij^2 rangle langle a_ij rangle\nlangle a_ija_ts rangle langle a_ij rangle langle a_ts rangle\nsigma^*(X) sqrtsum_ij left( sigma^*a_ij fracpartial Xpartial a_ij  right)^2_A = langle A^* rangle + dots \nsigma^*a_ij fracsqrte^-alpha_i - beta_j1+e^-alpha_i - beta_j","category":"page"},{"location":"models/DBCM/#Creation","page":"DBCM","title":"Creation","text":"","category":"section"},{"location":"models/DBCM/","page":"DBCM","title":"DBCM","text":"using Graphs\nusing MaxEntropyGraphs\n\n# define the network\nG = SimpleDiGraph(rhesus_macaques())\n\n# instantiate a UBCM model\nmodel = DBCM(G)","category":"page"},{"location":"models/DBCM/#Obtaining-the-parameters","page":"DBCM","title":"Obtaining the parameters","text":"","category":"section"},{"location":"models/DBCM/","page":"DBCM","title":"DBCM","text":"# solve using default settings\nsolve_model!(model)","category":"page"},{"location":"models/DBCM/#Sampling-the-ensemble","page":"DBCM","title":"Sampling the ensemble","text":"","category":"section"},{"location":"models/DBCM/","page":"DBCM","title":"DBCM","text":"# generate 10 random instance of the ensemble\nrand(model, 10)","category":"page"},{"location":"models/DBCM/#Model-comparison","page":"DBCM","title":"Model comparison","text":"","category":"section"},{"location":"models/DBCM/","page":"DBCM","title":"DBCM","text":"# compute the AIC  \nAIC(model)","category":"page"},{"location":"models/DBCM/#Counting-network-motifs","page":"DBCM","title":"Counting network motifs","text":"","category":"section"},{"location":"models/DBCM/","page":"DBCM","title":"DBCM","text":"The count of a specific network motif can be computed by using M{motif_number}. The motif numbers match the patterns shown on the image below. So for example if you want to compute the number of reciprocated triangles, you would use M13(model).","category":"page"},{"location":"models/DBCM/","page":"DBCM","title":"DBCM","text":"HTML(\"\"\"<object type=\"image/png\" data=$(joinpath(Main.buildpath, \"../assets/directed_motifs.png\"))  alt=\"Motif image not found\" style=\"width: 100%;\" ></object> \"\"\") # hide","category":"page"},{"location":"models/DBCM/","page":"DBCM","title":"DBCM","text":"source","category":"page"},{"location":"models/DBCM/","page":"DBCM","title":"DBCM","text":"# Compute the number of occurences of M13\nM13(model)","category":"page"},{"location":"models/DBCM/","page":"DBCM","title":"DBCM","text":"References","category":"page"},{"location":"models/DBCM/","page":"DBCM","title":"DBCM","text":"<ul>\n<li>\n<a id=\"1\">[1]</a> \nSquartini, Tiziano and Garlaschelli, Diego. <!--  author(s) --> \n<em>\"Maximum-Entropy Networks: Pattern Detection, Network Reconstruction and Graph Combinatorics\"</em> <!--  title --> \nSpringer-Verlag GmbH; 1st ed. 2017 edition (25 Dec. 2017). <!--  publisher(s) --> \n<a href=\"https://link.springer.com/book/10.1007/978-3-319-69438-2\">https://link.springer.com/book/10.1007/978-3-319-69438-2</a>\n</li>\n<li>\n<a id=\"2\">[2]</a> \nSquartini, Tiziano and Garlaschelli, Diego. <!--  author(s) --> \n<em>\"Analytical maximum-likelihood method to detect patterns in real networks\"</em> <!--  title --> \n2011 New J. Phys. 13 083001. <!--  publisher(s) --> \n<a href=\"https://iopscience.iop.org/article/10.1088/1367-2630/13/8/083001\">https://iopscience.iop.org/article/10.1088/1367-2630/13/8/083001</a>\n</li>\n</ul>","category":"page"},{"location":"exact/#Analytical","page":"Analytical","title":"Analytical","text":"","category":"section"},{"location":"exact/","page":"Analytical","title":"Analytical","text":"The maximum likelihood method can be used to compute the expected value and the standard deviation of any metric that is based on the adjacency matrix. Depending on the underlying model, some details change, but the principle remains. This formalism allows us to computed z-scores and assess which topological properties are consistent with their randomized value within a statistical error, and which deviate significantly from the null model expectation. In the latter case, the observed property cannot be traced back to the constraints, and therefore requires additional explanations or generating mechanisms besides those required in order to explain the constraints themselves. ","category":"page"},{"location":"exact/","page":"Analytical","title":"Analytical","text":"Some topological properties are available in the package default (e.g. ANND and different network motifs), but you can define an additional metrics as well. This allows you to obtain both the expected value and the standard deviation of any matrix in a standardised way. In the expression of the variance of a topological property X, we find fracpartial Xpartial a_ij. We use leverage Julia's autodiff capabilities to compute these terms. If desired, you can always compute the gradient of a specific metric by hand and implement it yourself as well. The downside of using this approach is that you need the complete adjacency matrix, so this is not suited for the analysis of very large graphs due to memory constraints. Depending on the size of the problem, different autodiff techniques can give different performance results. You might want to experiment a bit with this for your own use case (some examples are provided as well).  ","category":"page"},{"location":"exact/#Expected-value","page":"Analytical","title":"Expected value","text":"","category":"section"},{"location":"exact/","page":"Analytical","title":"Analytical","text":"Using the maximum likelihood method method the expected value for any topological property X can be computed from the expected values in the adjacency matrix of the graph G (this approximation ignores the second and higher order terms in the multidimensional Taylor expansion of X).","category":"page"},{"location":"exact/","page":"Analytical","title":"Analytical","text":"X left( G right)  =  X left( left G right right)","category":"page"},{"location":"exact/#Variance","page":"Analytical","title":"Variance","text":"","category":"section"},{"location":"exact/","page":"Analytical","title":"Analytical","text":"The variance of a topological property S can be written as follows","category":"page"},{"location":"exact/","page":"Analytical","title":"Analytical","text":"sigma ^2 left X right = sum_ij sum_ts sigma leftg_ij g_ts right left(  fracpartial Xpartial g_ij fracpartial Xpartial g_ts  right)_G = left G right","category":"page"},{"location":"exact/","page":"Analytical","title":"Analytical","text":"where","category":"page"},{"location":"exact/","page":"Analytical","title":"Analytical","text":"sigma left g_ij g_ts right = left g_ijg_tsright - left g_ijrightleft g_tsright","category":"page"},{"location":"exact/","page":"Analytical","title":"Analytical","text":"Using the appropriate expressions for  left g_ij right and left g_ijright (depending on the model considered, cf. examples), a highly reliable estimate for the variance of the metric can be obtained.","category":"page"},{"location":"exact/#Examples","page":"Analytical","title":"Examples","text":"","category":"section"},{"location":"exact/","page":"Analytical","title":"Analytical","text":"Some examples using built-in function of package are listed below:","category":"page"},{"location":"exact/","page":"Analytical","title":"Analytical","text":"Assortativity in the UBCM\nMotif significance in the UBCM","category":"page"},{"location":"exact/#Assortativity_analytical","page":"Analytical","title":"Assortativity in the UBCM","text":"","category":"section"},{"location":"exact/","page":"Analytical","title":"Analytical","text":"Let us consider the UBCM applied to the Zachary Karate Club network. We want to analyse if the assortativity of each node (measured by its ANND) is statistically significant from what one would expect under the null model.","category":"page"},{"location":"exact/","page":"Analytical","title":"Analytical","text":"First, we define the network and the associated UBCM model.","category":"page"},{"location":"exact/","page":"Analytical","title":"Analytical","text":"using Graphs\nusing MaxEntropyGraphs\n\n# define the network\nG = MaxEntropyGraphs.Graphs.SimpleGraphs.smallgraph(:karate)\n# generate a UBCM model from the karate club network\nmodel = UBCM(G); \n# compute the maximum likelihood parameters\nsolve_model!(model); \n# compute and set the expected adjacency matrix\nset_Ĝ!(model); \n# compute and set the standard deviation of the adjacency matrix\nset_σ!(model); \nnothing","category":"page"},{"location":"exact/","page":"Analytical","title":"Analytical","text":"Now we can define our specific metric. Before computing the z-score for all nodes, we illustrate the process for a single node. We use X as variable name for our metric. Defining methods for X in such a way that it can   with both an AbstractArray and an AbstractGraph is recommended, but not necessary.","category":"page"},{"location":"exact/","page":"Analytical","title":"Analytical","text":"# We consider the ANND of node 1 as our metric\nnode_id = 1\nX = A -> ANND(A, node_id, check_dimensions=false, check_directed=false);    \n# Expected value under the null model\nX_expected = X(model.Ĝ)\n# Expected standard deviation under the null model\nX_std = σₓ(model, X)\n# Observed value (using the underlying network)\nX_observed = X(model.G)\n# compute z-score\nz_X = (X_observed - X_expected) / X_std","category":"page"},{"location":"exact/","page":"Analytical","title":"Analytical","text":"In the same way, we can compute the z-score for every node:","category":"page"},{"location":"exact/","page":"Analytical","title":"Analytical","text":"# Observed value\nANND_obs = [ANND(G, i) for i in vertices(G)]\n# Expected values\nANND_exp = [ANND(model.Ĝ, i) for i in vertices(G)]\n# Standard deviation\nANND_std = [σₓ(model, A -> ANND(A, i, check_dimensions=false, check_directed=false)) for i in vertices(G)]\n# Z-score\nZ_ANND = (ANND_obs - ANND_exp) ./ ANND_std;","category":"page"},{"location":"exact/#Motif_analytical","page":"Analytical","title":"Motif significance in the UBCM","text":"","category":"section"},{"location":"exact/","page":"Analytical","title":"Analytical","text":"Let us consider the DBCM applied to the Chesapeake Bay foodweb. We want to analyse if any of the different network motifs is statistically significant of what one would expect uner the null model.","category":"page"},{"location":"exact/","page":"Analytical","title":"Analytical","text":"First, we define the network and the associated UBCM model.","category":"page"},{"location":"exact/","page":"Analytical","title":"Analytical","text":"using Graphs\nusing MaxEntropyGraphs\nimport Statistics: mean, std\n\n# define the network\nG = chesapeakebay()\n# extract its adjacency matrix\nA = adjacency_matrix(G)\n# generate a UBCM model from the karate club network\nmodel = DBCM(G); \n# compute the maximum likelihood parameters\nsolve_model!(model); \n# compute and set the expected adjacency matrix\nset_Ĝ!(model); \n# compute and set the standard deviation of the adjacency matrix\nset_σ!(model); \nnothing","category":"page"},{"location":"exact/","page":"Analytical","title":"Analytical","text":"We want to know the values of M1, ..., M13. These are network-wide measures. ","category":"page"},{"location":"exact/","page":"Analytical","title":"Analytical","text":"# compute the observed motif counts\nmotifs_observed = [@eval begin $(f)(A) end for f in MaxEntropyGraphs.directed_graph_motif_function_names];\n# Expected value under the null model\nmotifs_expected = [@eval begin $(f)(model) end for f in MaxEntropyGraphs.directed_graph_motif_function_names];\n# Expected standard deviation under the null model\nmotifs_std = [@eval begin  σₓ(model, $(f), gradient_method=:ForwardDiff) end for f in MaxEntropyGraphs.directed_graph_motif_function_names];\n# compute the z-score\nmotifs_z = (motifs_observed .- motifs_expected) ./ motifs_std","category":"page"},{"location":"models/BiCM/#BiCM","page":"BiCM","title":"BiCM","text":"","category":"section"},{"location":"models/BiCM/#Model-description","page":"BiCM","title":"Model description","text":"","category":"section"},{"location":"models/BiCM/","page":"BiCM","title":"BiCM","text":"An undirected bipartite network can be described by its biadjacency matrix B = left b_ialpha right_ialpha of size N times M whose generic entry b_iα is 1 if node i belonging to layer ⊥ is linked to node α belonging to layer ⊤ and 0 otherwise. The two sets of nodes (sometimes referred to a layers) are defined as as ⊥ and ⊤.  The Bipartite Configuration Model (BiCM) is a maximum-entropy null model for undirected bipartite networks.  It is based on the idea of fixing the degree sequences for each set of nodes (layers) of the network.  The model assumes that the edges are unweighted and that the network is simple, i.e., it has no self-loops or multiple edges between the same pair of nodes [1]. ","category":"page"},{"location":"models/BiCM/","page":"BiCM","title":"BiCM","text":"note: Note\nFor the computation we use the bi-adjacency matrix, whereas the current implementation of the BiCM uses a ::Graphs.SimpleGraph to construct the models and assesses its bipartiteness using the functionality available in the Graphs.jl package.","category":"page"},{"location":"models/BiCM/","page":"BiCM","title":"BiCM","text":"The parameter vector is defined as theta = gamma  beta, where gamma and beta denote the parameters associated with the ⊥ and ⊤ layer respectively. To speed up the computation of the likelihood maximising parameters,  we use the reduced version of the model where we consider the unique values the degrees in each layer [2].","category":"page"},{"location":"models/BiCM/","page":"BiCM","title":"BiCM","text":"Description Formula\nConstraints begincases forall i in bot  k_i(A^*) = sum_alpha in top b^*_ialpha   forall alpha in top  d_alpha(A^*) = sum_i in bot b^*_ialpha endcases\nHamiltonian H(A Theta) = H(A gamma beta) = sum_i in bot gamma_i k_i(A) +  sum_alpha in top beta_alpha d_alpha(A)\nFactorized graph probability P(A  Theta) = prod_i=1^Nprod_j=1^M p_ialpha^b_ialpha (1 - p_alpha)^1-b_ialpha\nlangle p_ialpha rangle p_ialpha = frace^-gamma_i - beta_alpha1+e^-gamma_i - beta_alpha\nLog-likelihood mathcalL(Theta) = -sum_i in bot gamma_i k_i(A) -  sum_alpha in top beta_alpha d_alpha(A) - sum_i in bot  sum_alpha in top ln left( 1 + e^-gamma_i - beta_alpha right)\nlangle p_ialpha^2 rangle \nlangle p_ialphaa_tkappa rangle \nsigma^*(X) \nsigma^*p_ialpha ","category":"page"},{"location":"models/BiCM/#Creation","page":"BiCM","title":"Creation","text":"","category":"section"},{"location":"models/BiCM/","page":"BiCM","title":"BiCM","text":"using Graphs\nusing MaxEntropyGraphs\n\n# define the network\nG =\n\n# instantiate a UBCM model\nmodel = BiCM(G)","category":"page"},{"location":"models/BiCM/#Obtaining-the-parameters","page":"BiCM","title":"Obtaining the parameters","text":"","category":"section"},{"location":"models/BiCM/","page":"BiCM","title":"BiCM","text":"# solve using default settings\nsolve_model!(model)","category":"page"},{"location":"models/BiCM/#Sampling-the-ensemble","page":"BiCM","title":"Sampling the ensemble","text":"","category":"section"},{"location":"models/BiCM/","page":"BiCM","title":"BiCM","text":"# generate 10 random instance of the ensemble\nrand(model, 10)","category":"page"},{"location":"models/BiCM/#Model-comparison","page":"BiCM","title":"Model comparison","text":"","category":"section"},{"location":"models/BiCM/","page":"BiCM","title":"BiCM","text":"# compute the AIC  \nAIC(model)","category":"page"},{"location":"models/BiCM/#Counting-network-motifs","page":"BiCM","title":"Counting network motifs","text":"","category":"section"},{"location":"models/BiCM/","page":"BiCM","title":"BiCM","text":"# Compute the number of occurences of M13\nM13(model)","category":"page"},{"location":"models/BiCM/","page":"BiCM","title":"BiCM","text":"References","category":"page"},{"location":"models/BiCM/","page":"BiCM","title":"BiCM","text":"<ul>\n<li>\n<a id=\"1\">[1]</a> \nM. Baltakiene, K. Baltakys, D. Cardamone, F. Parisi, T. Radicioni, M. Torricelli, J. A. van Lidth de Jeude, F. Saracco <!--  author(s) --> \n<em>\"Maximum entropy approach to link prediction in bipartite networks\"</em> <!--  title --> \n arXiv preprint arXiv:1805.04307 (2018). <!--  publisher(s) --> \n<a href=\"https://arxiv.org/abs/1805.04307\">https://arxiv.org/abs/1805.04307</a>\n</li>\n<li>\n<a id=\"2\">[2]</a> \nVallarano, N., Bruno, M., Marchese, E. et al. <!--  author(s) --> \n<em>\"Fast and scalable likelihood maximization for Exponential Random Graph Models with local constraints\"</em> <!--  title --> \nSci Rep 11, 15227 (2021) <!--  publisher(s) --> \n<a href=\"https://doi.org/10.1038/s41598-021-93830-4\">https://doi.org/10.1038/s41598-021-93830-4</a>\n</li>\n</ul>","category":"page"},{"location":"models/BiCM/","page":"BiCM","title":"BiCM","text":"Fast and scalable likelihood maximization for Exponential Random Graph Models with local constraints","category":"page"},{"location":"models/BiCM/","page":"BiCM","title":"BiCM","text":"Vallarano, N., Bruno, M., Marchese, E. et al. Fast and scalable likelihood maximization for Exponential Random Graph Models with local constraints. Sci Rep 11, 15227 (2021). https://doi.org/10.1038/s41598-021-93830-4","category":"page"},{"location":"models/UBCM/#UBCM","page":"UBCM","title":"UBCM","text":"","category":"section"},{"location":"models/UBCM/#Model-description","page":"UBCM","title":"Model description","text":"","category":"section"},{"location":"models/UBCM/","page":"UBCM","title":"UBCM","text":"The Undirected Binary Configuration Model is a maximum-entropy null model for undirected networks. It is based on the idea of fixing the degree sequence of the network, i.e., the number of edges incident to each node, and then randomly rewiring the edges while preserving the degree sequence. The model assumes that the edges are unweighted and that the network is simple, i.e., it has no self-loops or multiple edges between the same pair of nodes [1,2]. ","category":"page"},{"location":"models/UBCM/","page":"UBCM","title":"UBCM","text":"Description Formula\nConstraints k_i(A^*) = sum_j=1^N a^*_ij  text   (forall i)\nHamiltonian H(A Theta) = sum_i=1^N Theta_i k_i(A)\nFactorized graph probability P(A  Theta) = prod_i=1^Nprod_j=1 ji^N p_ij^a_ij (1 - p_ij)^1-a_ij\nlangle a_ij rangle p_ij = frace^-theta_i - theta_j1+e^-theta_i - theta_j\nLog-likelihood mathcalL(Theta) = -sum_i=1^Ntheta_i k_i(A^*) - sum_i=1^N sum_j=1 ji^N ln left( 1+e^-theta_i - theta_j right)\nlangle a_ij^2 rangle langle a_ij rangle\nlangle a_ija_ts rangle langle a_ij rangle langle a_ts rangle\nsigma^*(X) sqrtsum_ij left( sigma^*a_ij fracpartial Xpartial a_ij  right)^2_A = langle A^* rangle + dots \nsigma^*a_ij fracsqrte^-theta_i - theta_j1+e^-theta_i - theta_j","category":"page"},{"location":"models/UBCM/#Creation","page":"UBCM","title":"Creation","text":"","category":"section"},{"location":"models/UBCM/","page":"UBCM","title":"UBCM","text":"using Graphs\nusing MaxEntropyGraphs\n\n# define the network\nG = smallgraph(:karate)\n\n# instantiate a UBCM model\nmodel = UBCM(G)","category":"page"},{"location":"models/UBCM/#Obtaining-the-parameters","page":"UBCM","title":"Obtaining the parameters","text":"","category":"section"},{"location":"models/UBCM/","page":"UBCM","title":"UBCM","text":"# solve using default settings\nsolve_model!(model)","category":"page"},{"location":"models/UBCM/#Sampling-the-ensemble","page":"UBCM","title":"Sampling the ensemble","text":"","category":"section"},{"location":"models/UBCM/","page":"UBCM","title":"UBCM","text":"# generate 10 random instance of the ensemble\nrand(model, 10)","category":"page"},{"location":"models/UBCM/#Model-comparison","page":"UBCM","title":"Model comparison","text":"","category":"section"},{"location":"models/UBCM/","page":"UBCM","title":"UBCM","text":"# compute the AIC  \nAIC(model)","category":"page"},{"location":"models/UBCM/","page":"UBCM","title":"UBCM","text":"References","category":"page"},{"location":"models/UBCM/","page":"UBCM","title":"UBCM","text":"<ul>\n<li>\n<a id=\"1\">[1]</a> \nSquartini, Tiziano and Garlaschelli, Diego. <!--  author(s) --> \n<em>\"Maximum-Entropy Networks: Pattern Detection, Network Reconstruction and Graph Combinatorics\"</em> <!--  title --> \nSpringer-Verlag GmbH; 1st ed. 2017 edition (25 Dec. 2017). <!--  publisher(s) --> \n<a href=\"https://link.springer.com/book/10.1007/978-3-319-69438-2\">https://link.springer.com/book/10.1007/978-3-319-69438-2</a>\n</li>\n<li>\n<a id=\"2\">[2]</a> \nSquartini, Tiziano and Garlaschelli, Diego. <!--  author(s) --> \n<em>\"Analytical maximum-likelihood method to detect patterns in real networks\"</em> <!--  title --> \n2011 New J. Phys. 13 083001. <!--  publisher(s) --> \n<a href=\"https://iopscience.iop.org/article/10.1088/1367-2630/13/8/083001\">https://iopscience.iop.org/article/10.1088/1367-2630/13/8/083001</a>\n</li>\n</ul>","category":"page"},{"location":"models/#Overview","page":"Overview","title":"Overview","text":"","category":"section"},{"location":"models/#Common-interface","page":"Overview","title":"Common interface","text":"","category":"section"},{"location":"models/","page":"Overview","title":"Overview","text":"All models share a common interface:","category":"page"},{"location":"models/","page":"Overview","title":"Overview","text":"A model (<:AbstractMaxEntropyModel) can be instantiated either from a graph (<:AbstractGraph) or by the model's constraint vector(s). \nThe parameters of a model can be computed with solve_model!.\nThe expected adjacency matrix can be obtained with Ĝ, where applicable the weights can be obtained with Ŵ.\nA random network can be sampled from the ensemble with rand\nInformation criteria are available to allow for model compairison through the Akaike Information Criterium (AIC) and the Bayesian Information Criterion (BIC).","category":"page"},{"location":"models/","page":"Overview","title":"Overview","text":"Please refer to the page of each specific model for more details.","category":"page"},{"location":"models/#Solution-methods","page":"Overview","title":"Solution methods","text":"","category":"section"},{"location":"models/","page":"Overview","title":"Overview","text":"Computing the parameters of a model can be done with different approaches. Either by running an optimisation algorithm on the Loglikelihood of the model (and thus implicitely solving a system of equations for the gradient of the loglikelihood of the model) [1] or by using a fixed point approach [2]. In both cases, we have also included the acceleration method that was proposed in [2] for nodes sharing the same (pair of) constraints.","category":"page"},{"location":"models/","page":"Overview","title":"Overview","text":"note: Note\nAlthough it is technically possible to run the computation of the likelihood maximising parameters in a precision lower than Float64, experiments have shown that this might leads to convergence problems.","category":"page"},{"location":"models/#Sampling","page":"Overview","title":"Sampling","text":"","category":"section"},{"location":"models/","page":"Overview","title":"Overview","text":"We have extend Base.rand to accept substypes of ::AbstractMaxEntropyModel. When working with larger network, it might not always be desirable to keep the entire expected adjacency matrix in memory, so by default this option is not used. Specifying a number of samples will return a vector of the appropriate substype of  ::AbstractGraph. Multithreading will be used if available to generate multiple graphs in parallel.","category":"page"},{"location":"models/#Differences-and-similarities-with-the-NEMtropy-package","page":"Overview","title":"Differences and similarities with the NEMtropy package","text":"","category":"section"},{"location":"models/","page":"Overview","title":"Overview","text":"We use the JuliaGraphs ecosystem for everything network related, whereas NEMtropy requires you to work with degree sequences, adjacency matrices or edge lists. These option are also available, either directly (in the case of degree sequences) or indirectly (by passing through the JuliaGraphs ecosystem).\nTo obtain the maximum likelihood parameters of a model we use either:\nthe well-established Optimization.jl package (this maximises the loglikelihood of the networks ensemble). Working this way uses automated differentiation, but explicit non-allocating gradient functions are also provided for the different models.\nNLsolve.jl's Anderson acceleration for the fixed point methods proposed in [4] (cf. documentation/examples). The iterative methods are non-allocating, so they are orders of magnitude faster than the Python implementation.\nWe have also maintained the different options for the initial values for each method (cf. initial_guess(::AbstractMaxEntropyModel)).\nBy making use of the automatic differentiation capabilities of Julia, we can:\napproximation the gradient of the likelihood function of the graphs\ncompute the gradient of any metric with respect to its adjacency matrix without having to compute these by hand and implement the partial derivative for each possible metric (cf. examples for more details on this).\nFor both the models and the computing functions we make a clear distinction between the likelihood maximising paramers and the variable substitution (e.g. theta_i leftrightarrow x_i = e^-theta_i for the UBCM). Doing so makes the code more readable because it is closer to the mathematical formulation.\nSampling from an <:AbstractMaxEntropyModel will generate a corresponding subtype of  <:AbstractGraph from the JuliaGraphs ecosystem. The methods that are available in Graphs.jl, SimpleWeightedGraphs etc. have been extended for the different maximum entropy models wherever applicable. ","category":"page"},{"location":"models/","page":"Overview","title":"Overview","text":"References","category":"page"},{"location":"models/","page":"Overview","title":"Overview","text":"<ul>\n<li>\n<a id=\"1\">[1]</a> \nSquartini, Tiziano and Garlaschelli, Diego. <!--  author(s) --> \n<em>\"Maximum-Entropy Networks: Pattern Detection, Network Reconstruction and Graph Combinatorics\"</em> <!--  title --> \nSpringer-Verlag GmbH; 1st ed. 2017 edition (25 Dec. 2017). <!--  publisher(s) --> \n<a href=\"https://link.springer.com/book/10.1007/978-3-319-69438-2\">https://link.springer.com/book/10.1007/978-3-319-69438-2</a>\n</li>\n</ul>\n\n<ul>\n<li>\n<a id=\"2\">[2]</a> \nVallarano, Nicolò and Bruno, Matteo and Marchese, Emiliano and Trapani, Giuseppe and Saracco, Fabio and Cimini, Giulio and Zanon, Mario and Squartini, Tiziano. <!--  author(s) --> \n<em>\"Fast and scalable likelihood maximization for Exponential Random Graph Models with local constraints\"</em> <!--  title --> \nScientific Reports 11, 2021. <!--  publisher(s) --> \n<a href=\"https://doi.org/10.1038/s41598-021-93830-4\">https://doi.org/10.1038/s41598-021-93830-4</a>\n</li>\n</ul>","category":"page"},{"location":"simulated/#Simulation","page":"Simulation","title":"Simulation","text":"","category":"section"},{"location":"simulated/","page":"Simulation","title":"Simulation","text":"The analytical method can quickly become expensive to compute since each element in the adjacency matrix has a non-zero value. It is also possible to obtain an estimate of both the metric and its standard deviation by generating a large number of random graphs from the ensemble and by computing the value of the metric(s) for each graph. This can also allow you to compute the z-scores of the metric, but some caution is advised. Using the analytical method, we do consider the actual underlying distribution of the metric to combine the expected value and standard deviation. This contrasts with the sample, where we simply apply the mean and standard deviation to the vector of computed metrics. Also, considering the z-score and interpreting statistical significance if z ge 3 implies that the underlying distribution of the metric follows a standard normal distribution, which is not always the case.","category":"page"},{"location":"simulated/#Examples","page":"Simulation","title":"Examples","text":"","category":"section"},{"location":"simulated/","page":"Simulation","title":"Simulation","text":"Some examples using built-in function of package are listed below:","category":"page"},{"location":"simulated/","page":"Simulation","title":"Simulation","text":"Assortativity in the UBCM\nMotif significance in the UBCM","category":"page"},{"location":"simulated/#Assortativity_simulation","page":"Simulation","title":"Assortativity in the UBCM","text":"","category":"section"},{"location":"simulated/","page":"Simulation","title":"Simulation","text":"Let us consider the UBCM applied to the Zachary Karate Club network. We want to analyse if the assortativity of each node (measured by its ANND) is statistically significant from what one would expect under the null model.","category":"page"},{"location":"simulated/","page":"Simulation","title":"Simulation","text":"First, we define the network and the associated UBCM model.","category":"page"},{"location":"simulated/","page":"Simulation","title":"Simulation","text":"using Graphs\nusing MaxEntropyGraphs\n\n# define the network\nG = MaxEntropyGraphs.Graphs.SimpleGraphs.smallgraph(:karate)\n# generate a UBCM model from the karate club network\nmodel = UBCM(G); \n# compute the maximum likelihood parameters\nsolve_model!(model); \n# compute and set the expected adjacency matrix\nset_Ĝ!(model); \n# compute and set the standard deviation of the adjacency matrix\nset_σ!(model); \nnothing","category":"page"},{"location":"simulated/#Motif_simulation","page":"Simulation","title":"Motif significance in the UBCM","text":"","category":"section"},{"location":"simulated/","page":"Simulation","title":"Simulation","text":"Let us consider the DBCM applied to the Chesapeake Bay foodweb. We want to analyse if any of the different network motifs is statistically significant of what one would expect uner the null model. We want to know the values of M1, ..., M13. These are network-wide measures. ","category":"page"},{"location":"simulated/","page":"Simulation","title":"Simulation","text":"First, we define the network and the associated UBCM model.","category":"page"},{"location":"simulated/","page":"Simulation","title":"Simulation","text":"using Graphs\nusing MaxEntropyGraphs\nimport Statistics: mean, std\n\n# define the network\nG = chesapeakebay();\n# extract its adjacency matrix\nA = adjacency_matrix(G);\n# generate a UBCM model from the karate club network\nmodel = DBCM(G); \n# compute the maximum likelihood parameters\nsolve_model!(model); \n# compute and set the expected adjacency matrix\nset_Ĝ!(model); \n# compute and set the standard deviation of the adjacency matrix\nset_σ!(model); \n# compute the observed motif counts\nmotifs_observed = [@eval begin $(f)(A) end for f in MaxEntropyGraphs.directed_graph_motif_function_names];\nnothing","category":"page"},{"location":"simulated/","page":"Simulation","title":"Simulation","text":"Now we need to generate a sample from the network ensemble so that we can compute the sample mean and standard deviation for each motif.","category":"page"},{"location":"simulated/","page":"Simulation","title":"Simulation","text":"# Get sample adjacency matrix\nS = adjacency_matrix.(rand(model, 100));\n# compute the motifs\nmotif_counts_S = hcat(map(s -> [@eval begin $(f)($s) end for f in MaxEntropyGraphs.directed_graph_motif_function_names], S)...);\n# compute the sample mean and standard deviation\nmotifs_mean_S = reshape(mean(motif_counts_S, dims=2),:);\nmotifs_std_S = reshape(std(motif_counts_S, dims=2),:);\n# compute the z-score\nmotifs_z_S = (motifs_observed .- motifs_mean_S) ./ motifs_std_S;\nnothing","category":"page"},{"location":"API/#API","page":"API","title":"API","text":"","category":"section"},{"location":"API/#Index","page":"API","title":"Index","text":"","category":"section"},{"location":"API/","page":"API","title":"API","text":"Pages = [\"API.md\"]","category":"page"},{"location":"API/#Global","page":"API","title":"Global","text":"","category":"section"},{"location":"API/","page":"API","title":"API","text":"MaxEntropyGraphs\nAbstractMaxEntropyModel\nMaxEntropyGraphs.ConvergenceError\n","category":"page"},{"location":"API/#MaxEntropyGraphs","page":"API","title":"MaxEntropyGraphs","text":"MaxEntropyGraphs\n\nJulia module for working with maximum entropy graphs\n\n\n\n\n\n","category":"module"},{"location":"API/#MaxEntropyGraphs.AbstractMaxEntropyModel","page":"API","title":"MaxEntropyGraphs.AbstractMaxEntropyModel","text":"AbstractMaxEntropyModel\n\nAn abstract type for a MaxEntropyModel. Each model has one or more structural constraints   that are fixed while the rest of the network is completely random. \n\n\n\n\n\n","category":"type"},{"location":"API/#MaxEntropyGraphs.ConvergenceError","page":"API","title":"MaxEntropyGraphs.ConvergenceError","text":"ConvergenceError\n\nException thrown when the optimisation method does not converge. \n\nWhen using and optimisation method from the optimisation.jl framework, the return code of the optimisation method is stored in the retcode field. When using the fixed point iteration method, the retcode field is set to nothing.\n\n\n\n\n\n","category":"type"},{"location":"API/#Utility-fuctions","page":"API","title":"Utility fuctions","text":"","category":"section"},{"location":"API/","page":"API","title":"API","text":"Some specific utility functions are made available:","category":"page"},{"location":"API/","page":"API","title":"API","text":"MaxEntropyGraphs.log_nan\nMaxEntropyGraphs.np_unique_clone","category":"page"},{"location":"API/#MaxEntropyGraphs.log_nan","page":"API","title":"MaxEntropyGraphs.log_nan","text":"log_nan(x::T)\n\nSame as log(x), but returns NaN if x <= 0. Inspired by NaNMath.jl and https://github.com/JuliaMath/NaNMath.jl/issues/63. This methods is prefered over the ones from NaNMath.jl version because it does not require a foreign call expression to be evaluated, hence autodiff methods can be used with this.\n\nExamples\n\njulia> MaxEntropyGraphs.log_nan(10.)\n2.302585092994046\n\njulia> MaxEntropyGraphs.log_nan(-10.)\nNaN\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.np_unique_clone","page":"API","title":"MaxEntropyGraphs.np_unique_clone","text":"np_unique_clone(x::Vector; sorted::Bool=false)\n\nJulia replication of the numpy.unique(a, returncounts=True, returnindex=True, return_inverse=True) function from Python.\n\nReturns a tuple of:\n\nvector of unique values in x\nvector of indices of the first occurence of each unique value in x. Follows the same order as the unique values.\nvector of inverse indices of the original data in the unique values\nvector of the counts of the unique values in x. Follows the same order as the unique values.\n\nIf sorted is true, the unique values are sorted by size and the other vectors are sorted accordingly.\n\nExamples\n\njulia> x = [1;2;2;4;1];\n\njulia> np_unique_clone(x)\n([1, 2, 4], [1, 2, 4], [1, 2, 2, 3, 1], [2, 2, 1])\n\njulia> x = [10;9;9;8];\n\njulia> np_unique_clone(x, sorted=true)\n([8, 9, 10], [4, 2, 1], [3, 2, 2, 1], [1, 2, 1])\n\n\n\n\n\n","category":"function"},{"location":"API/#Small-graph-constructors","page":"API","title":"Small graph constructors","text":"","category":"section"},{"location":"API/","page":"API","title":"API","text":"MaxEntropyGraphs.taro_exchange\nMaxEntropyGraphs.rhesus_macaques\nMaxEntropyGraphs.chesapeakebay\nMaxEntropyGraphs.everglades\nMaxEntropyGraphs.florida\nMaxEntropyGraphs.littlerock\nMaxEntropyGraphs.maspalomas\nMaxEntropyGraphs.stmarks\nMaxEntropyGraphs.parse_konect\nMaxEntropyGraphs.readpajek","category":"page"},{"location":"API/#MaxEntropyGraphs.taro_exchange","page":"API","title":"MaxEntropyGraphs.taro_exchange","text":"taro_exchange()\n\nA small directed network that contains gift-givings (taro) between households in a Papuan village. A node represents a household and an edge between two households indicates that there happened a gift-giving. The network is directed and contains 22 nodes and 78 edges.\n\nSee also: KONECT\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.rhesus_macaques","page":"API","title":"MaxEntropyGraphs.rhesus_macaques","text":"rhesus_maqaques()\n\nA small weighted, directed network that contains observed grooming episodes between free ranging rhesus macaques (Macaca mulatta) in Cayo Santiago during a two month period in 1963. Cayo Santiago is an island off the coast of Puerto Rico, also known as Isla de los monos (Island of the monkeys). A node represents a monkey and a directed edge A → B denotes that the rhesus macaque A groomed rhesus macaque B. The integer edge weights indicate how often this behaviour was observed.\n\nSee also: KONECT\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.chesapeakebay","page":"API","title":"MaxEntropyGraphs.chesapeakebay","text":"chesapeakebay()\n\nA small foodweb (directed network) of the Chesapeake Bay. \n\nOriginal data available here\n\nSee also: MaxEntropyGraphs.readpajek\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.everglades","page":"API","title":"MaxEntropyGraphs.everglades","text":"everglades()\n\nA small foodweb (directed network) of the Everglades. \n\nOriginal data available here\n\nSee also: MaxEntropyGraphs.readpajek\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.florida","page":"API","title":"MaxEntropyGraphs.florida","text":"florida()\n\nA small foodweb (directed network) of the Florida Bay. \n\nOriginal data available here\n\nSee also: MaxEntropyGraphs.readpajek\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.littlerock","page":"API","title":"MaxEntropyGraphs.littlerock","text":"littlerock()\n\nA small foodweb (directed network) of the Little Rock Lake. \n\nOriginal data available here\n\nSee also: MaxEntropyGraphs.parse_konect\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.maspalomas","page":"API","title":"MaxEntropyGraphs.maspalomas","text":"maspalomas()\n\nA small foodweb (directed network) from Charca de Maspalomas. \n\nOriginal data available here\n\nSee also: MaxEntropyGraphs.readpajek\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.stmarks","page":"API","title":"MaxEntropyGraphs.stmarks","text":"stmarks()\n\nA small foodweb (directed network) from the St. Marks River. \n\nOriginal data available here\n\nSee also: MaxEntropyGraphs.readpajek\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.parse_konect","page":"API","title":"MaxEntropyGraphs.parse_konect","text":"parse_konect(content::String)\n\nHelper function to parse network data from the KONECT Project and return it to a graph object in the JuliaGraphs ecosystem.\n\nExamples\n\n# read the data from a file\nG = open(io -> parse_konect(read(io, String)), \"/path/to/KONECT/network/data\")\n# store the graph in Graphs.jl format\nsavegraph(\"path/to/my_KONECT_graph.lgz\", G)\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.readpajek","page":"API","title":"MaxEntropyGraphs.readpajek","text":"readpajek(f::String; is_directed::Bool=true)\n\nhelper function to load a network from the pajek dataset and return it to a graph object in the JuliaGraphs ecosystem.\n\nFor this simple helper, weights are discarded.\n\n\n\n\n\n","category":"function"},{"location":"API/#Graph-metrics","page":"API","title":"Graph metrics","text":"","category":"section"},{"location":"API/","page":"API","title":"API","text":"MaxEntropyGraphs.degree\nMaxEntropyGraphs.outdegree\nMaxEntropyGraphs.indegree\nMaxEntropyGraphs.strength\nMaxEntropyGraphs.outstrength\nMaxEntropyGraphs.instrength\nMaxEntropyGraphs.ANND\nMaxEntropyGraphs.ANND_out\nMaxEntropyGraphs.ANND_in\nMaxEntropyGraphs.wedges\nMaxEntropyGraphs.triangles\nMaxEntropyGraphs.squares\nMaxEntropyGraphs.a⭢\nMaxEntropyGraphs.a⭠\nMaxEntropyGraphs.a⭤\nMaxEntropyGraphs.a̲\nMaxEntropyGraphs.M1\nMaxEntropyGraphs.M2\nMaxEntropyGraphs.M3\nMaxEntropyGraphs.M4\nMaxEntropyGraphs.M5\nMaxEntropyGraphs.M6\nMaxEntropyGraphs.M7\nMaxEntropyGraphs.M8\nMaxEntropyGraphs.M9\nMaxEntropyGraphs.M10\nMaxEntropyGraphs.M11\nMaxEntropyGraphs.M12\nMaxEntropyGraphs.M13","category":"page"},{"location":"API/#MaxEntropyGraphs.degree","page":"API","title":"MaxEntropyGraphs.degree","text":"degree(m::UBCM, i::Int; method=:reduced)\n\nReturn the expected degree vector for node i of the UBCM model m. Uses the reduced model parameters xᵣ for perfomance reasons.\n\nArguments\n\nm::UBCM: the UBCM model\ni::Int: the node for which to compute the degree.\nmethod::Symbol: the method to use for computing the degree. Can be any of the following:\n:reduced (default) uses the reduced model parameters xᵣ for perfomance reasons.\n:full uses all elements of the expected adjacency matrix.\n:adjacency uses the precomputed adjacency matrix m.Ĝ of the model.\n\nExamples\n\njulia> model = UBCM(MaxEntropyGraphs.Graphs.SimpleGraphs.smallgraph(:karate));\n\njulia> solve_model!(model);\n\njulia> set_Ĝ!(model);\n\njulia> typeof([degree(model, 1), degree(model, 1, method=:full), degree(model, 1, method=:adjacency)])\nVector{Float64} (alias for Array{Float64, 1})\n\n\n\n\n\n\ndegree(m::UBCM[, v]; method=:reduced)\n\nReturn a vector corresponding to the expected degree of the UBCM model m each node. If v is specified, only return degrees for nodes in v.\n\nArguments\n\nm::UBCM: the UBCM model\nv::Vector{Int}: the nodes for which to compute the degree. Default is all nodes.\nmethod::Symbol: the method to use for computing the degree. Can be any of the following:\n:reduced (default) uses the reduced model parameters xᵣ for perfomance reasons.\n:full uses all elements of the expected adjacency matrix.\n:adjacency uses the precomputed adjacency matrix m.Ĝ of the model.\n\nExamples\n\njulia> model = UBCM(MaxEntropyGraphs.Graphs.SimpleGraphs.smallgraph(:karate));\n\njulia> solve_model!(model);\n\njulia> set_Ĝ!(model);\n\njulia> typeof(degree(model, method=:adjacency)) \nVector{Float64} (alias for Array{Float64, 1})\n\n\n\n\n\n\ndegree(m::DBCM, i::Int; method=:reduced)\n\nIn alignment with Graphs.jl, returns the sum of the expected out- and indegree for node i of the DBCM model m. Uses the reduced model parameters xᵣ for perfomance reasons.\n\nArguments\n\nm::DBCM: the DBCM model\ni::Int: the node for which to compute the degree.\nmethod::Symbol: the method to use for computing the degree. Can be any of the following:\n:reduced (default) uses the reduced model parameters xᵣ for perfomance reasons.\n:full uses all elements of the expected adjacency matrix.\n:adjacency uses the precomputed adjacency matrix m.Ĝ of the model.\n\nExamples\n\njulia> model = DBCM(MaxEntropyGraphs.Graphs.SimpleDiGraph(rhesus_macaques()));\n\njulia> solve_model!(model);\n\njulia> set_Ĝ!(model);\n\njulia> typeof([degree(model, 1), degree(model, 1, method=:full), degree(model, 1, method=:adjacency)])\nVector{Float64} (alias for Array{Float64, 1})\n\n\n\n\n\n\ndegree(m::DBCM[, v]; method=:reduced)\n\nIn alignment with Graphs.jl, returns a vector corresponding to the sum of the expected out- and indegree of the DBCM model m each node. If v is specified, only return indegrees for nodes in v.\n\nArguments\n\nm::DBCM: the DBCM model\nv::Vector{Int}: the nodes for which to compute the degree. Default is all nodes.\nmethod::Symbol: the method to use for computing the degree. Can be any of the following:\n:reduced (default) uses the reduced model parameters xᵣ for perfomance reasons.\n:full uses all elements of the expected adjacency matrix.\n:adjacency uses the precomputed adjacency matrix m.Ĝ of the model.\n\nExamples\n\njulia> model = DBCM(MaxEntropyGraphs.Graphs.SimpleDiGraph(rhesus_macaques()));\n\njulia> solve_model!(model);\n\njulia> set_Ĝ!(model);\n\njulia> typeof(degree(model, method=:adjacency)) \nVector{Float64} (alias for Array{Float64, 1})\n\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.outdegree","page":"API","title":"MaxEntropyGraphs.outdegree","text":"outdegree(m::DBCM, i::Int; method=:reduced)\n\nReturn the expected degree vector for node i of the DBCM model m. Uses the reduced model parameters xᵣ for perfomance reasons.\n\nArguments\n\nm::DBCM: the DBCM model\ni::Int: the node for which to compute the degree.\nmethod::Symbol: the method to use for computing the degree. Can be any of the following:\n:reduced (default) uses the reduced model parameters xᵣ for perfomance reasons.\n:full uses all elements of the expected adjacency matrix.\n:adjacency uses the precomputed adjacency matrix m.Ĝ of the model.\n\nExamples\n\njulia> model = DBCM(MaxEntropyGraphs.Graphs.SimpleDiGraph(rhesus_macaques()));\n\njulia> solve_model!(model);\n\njulia> set_Ĝ!(model);\n\njulia> typeof([outdegree(model, 1), outdegree(model, 1, method=:full), outdegree(model, 1, method=:adjacency)])\nVector{Float64} (alias for Array{Float64, 1})\n\n\n\n\n\n\noutdegree(m::DBCM[, v]; method=:reduced)\n\nReturn a vector corresponding to the expected outdegree of the DBCM model m each node. If v is specified, only return outdegrees for nodes in v.\n\nArguments\n\nm::DBCM: the DBCM model\nv::Vector{Int}: the nodes for which to compute the outdegree. Default is all nodes.\nmethod::Symbol: the method to use for computing the outdegree. Can be any of the following:\n:reduced (default) uses the reduced model parameters xᵣ for perfomance reasons.\n:full uses all elements of the expected adjacency matrix.\n:adjacency uses the precomputed adjacency matrix m.Ĝ of the model.\n\nExamples\n\njulia> model = DBCM(MaxEntropyGraphs.Graphs.SimpleDiGraph(rhesus_macaques()));\n\njulia> solve_model!(model);\n\njulia> set_Ĝ!(model);\n\njulia> typeof(outdegree(model, method=:adjacency)) \nVector{Float64} (alias for Array{Float64, 1})\n\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.indegree","page":"API","title":"MaxEntropyGraphs.indegree","text":"indegree(m::DBCM, i::Int; method=:reduced)\n\nReturn the expected degree vector for node i of the DBCM model m. Uses the reduced model parameters xᵣ for perfomance reasons.\n\nArguments\n\nm::DBCM: the DBCM model\ni::Int: the node for which to compute the degree.\nmethod::Symbol: the method to use for computing the degree. Can be any of the following:\n:reduced (default) uses the reduced model parameters xᵣ for perfomance reasons.\n:full uses all elements of the expected adjacency matrix.\n:adjacency uses the precomputed adjacency matrix m.Ĝ of the model.\n\nExamples\n\njulia> model = DBCM(MaxEntropyGraphs.Graphs.SimpleDiGraph(rhesus_macaques()));\n\njulia> solve_model!(model);\n\njulia> set_Ĝ!(model);\n\njulia> typeof([indegree(model, 1), indegree(model, 1, method=:full), indegree(model, 1, method=:adjacency)])\nVector{Float64} (alias for Array{Float64, 1})\n\n\n\n\n\n\nindegree(m::DBCM[, v]; method=:reduced)\n\nReturn a vector corresponding to the expected indegree of the DBCM model m each node. If v is specified, only return indegrees for nodes in v.\n\nArguments\n\nm::DBCM: the DBCM model\nv::Vector{Int}: the nodes for which to compute the indegree. Default is all nodes.\nmethod::Symbol: the method to use for computing the indegree. Can be any of the following:\n:reduced (default) uses the reduced model parameters xᵣ for perfomance reasons.\n:full uses all elements of the expected adjacency matrix.\n:adjacency uses the precomputed adjacency matrix m.Ĝ of the model.\n\nExamples\n\njulia> model = DBCM(MaxEntropyGraphs.Graphs.SimpleDiGraph(rhesus_macaques()));\n\njulia> solve_model!(model);\n\njulia> set_Ĝ!(model);\n\njulia> typeof(indegree(model, method=:adjacency)) \nVector{Float64} (alias for Array{Float64, 1})\n\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.strength","page":"API","title":"MaxEntropyGraphs.strength","text":"strength(G, T; dir)\n\nConstruct the strength vector for the graph G, filled with element type T and considering edge direction dir ∈ [:in, :out, :both] (default is :out).\n\n\n\n\n\nstrength(G, i, T; dir)\n\nConstruct the strength of node i for the graph G, filled with element type T and considering edge direction dir ∈ [:in, :out, :both] (default is :out).\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.outstrength","page":"API","title":"MaxEntropyGraphs.outstrength","text":"instrength(G, T; dir)\n\nConstruct the outstrength vector for the graph G, filled with element type T.\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.instrength","page":"API","title":"MaxEntropyGraphs.instrength","text":"instrength(G, T; dir)\n\nConstruct the instrength vector for the graph G, filled with element type T.\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.ANND","page":"API","title":"MaxEntropyGraphs.ANND","text":"ANND(G::T, i::Int; check_directed::Bool=true) where {T<:Graphs.AbstractGraph}\n\nCompute the average nearest neighbor degree (ANND) for node i in graph G. The ANND for a node i is defined as ANND_i(A^*) = fracsum_j=1^N a_ijk_j k_i where a_ij denotes the element of the adjacency matrix A at row i and column j, and k_i denotes the degree of node i.\n\nNotes: \n\nthe ANND is only defined for nodes with nonzero degree. If degree(G,i) = 0, then ANND(G,i) = 0.\nif G is a directed graph, by default an error is thrown because the degree function returns the incoming plus outgoing edges for node i in this case.   This can be turned off by setting check_directed=false.\n\nExamples\n\njulia> using Graphs\n\njulia> G = smallgraph(:karate);\n\njulia> ANND(G,1)\n4.3125\n\n\njulia> add_vertex!(G);\n\njulia> ANND(G, nv(G))\n0.0\n\njulia> Gd = SimpleDiGraph(G);\n\njulia> ANND(Gd,1)\nERROR: ArgumentError: The graph is directed. The degree function returns the incoming plus outgoing edges for node `i`. Consider using ANND_in or ANND_out instead.\n[...]\n\njulia> ANND(Gd,1, check_directed=false)\n4.3125\n\nSee also: ANND_in, ANND_out, Graphs.degree\n\n\n\n\n\nANND(G::T, vs=vertices(G); check_directed::Bool=true) where {T<:Graphs.AbstractGraph}\n\nReturn a vector correcponding to the average nearest neighbor degree (ANND) all nodes in the graph G.  If v is specified, only return the ANND for nodes in v. The ANND for a node i is defined as  ANND_i(A^*) = fracsum_j=1^N a_ijk_j k_i where a_ij denotes the element of the adjacency matrix A at row i and column j, and k_i denotes the degree of node i.\n\nNotes: \n\nthe ANND is only defined for nodes with nonzero degree. If degree(G,i) = 0, then ANND(G,i) = 0.\nif G is a directed graph, by default an error is thrown because the degree function returns the incoming plus outgoing edges for node i in this case.\n\nThis can be turned off by setting check_directed=false. This check is only performed once the actual computing.\n\nExamples\n\njulia> using Graphs\n\njulia> G = smallgraph(:karate);\n\njulia> ANND(G,[10; 20; 30])\n3-element Vector{Float64}:\n 13.5\n 14.0\n  9.0\n\n\njulia> Gd = SimpleDiGraph(G);\n\njulia> ANND(Gd,[10; 20; 30]);\nERROR: ArgumentError: The graph is directed. The degree function returns the incoming plus outgoing edges for node `i`. Consider using ANND_in or ANND_out instead.\n[...]\n\njulia> ANND(Gd,[10; 20; 30], check_directed=false)\n3-element Vector{Float64}:\n 13.5\n 14.0\n  9.0\n\n\nSee also: ANND_in, ANND_out, Graphs.degree\n\n\n\n\n\nANND(A::T, i::Int; check_dimensions::Bool=true, check_directed::Bool=true) where {T<:AbstractMatrix}\n\nCompute the average nearest neighbor degree (ANND) for node i using adjacency matrix A. The ANND for a node i is defined as ANND_i(A^*) = fracsum_j=1^N a_ijk_j k_i where a_ij denotes the element of the adjacency matrix A at row i and column j, and k_i denotes the degree of node i.\n\nNotes: \n\nthis function is intented for use with the expected adjacency matrix of a ::AbstractMaxEntropyModel model. A separate method exists for ::AbstractGraph objects.\nif A is not symmetrical, you have a directed graph, and this will throw an error by default. This can be turned off by setting check_directed=false.\nthe adjacency matrix should be square, if not, this will throw an error by default. This can be turned off by setting check_dimensions=false.\n\nExamples\n\njulia> using Graphs\n\njulia> G = smallgraph(:karate);\n\njulia> A = adjacency_matrix(G);\n\njulia> ANND(A, 1)\n4.3125\n\n\njulia> Gd = SimpleDiGraph(G);\n\njulia> add_vertex!(Gd); add_edge!(Gd, 1, nv(Gd));\n\njulia> Ad = adjacency_matrix(Gd);\n\njulia> ANND(Ad, 1)\nERROR: ArgumentError: The matrix is not symmetrical. Consider using ANND_in or ANND_out instead.\n[...]\n\njulia> ANND(Ad, 1, check_directed=false)\n4.375\n\n\njulia> ANND(rand(2,3),1)\nERROR: DimensionMismatch: `A` must be a square matrix.\n[...]\n\nSee also: ANND_in, ANND_out, Graphs.degree\n\n\n\n\n\nANND(A::T, vs=1:size(A,1); check_dimensions::Bool=true, check_directed::Bool=true) where {T<:AbstractMatrix}\n\nReturn a vector correcponding to the average nearest neighbor degree (ANND) all nodes in the graph with adjacency matrix A.  If v is specified, only return the ANND for nodes in v. The ANND for a node i is defined as  ANND_i(A^*) = fracsum_j=1^N a_ijk_j k_i where a_ij denotes the element of the adjacency matrix A at row i and column j, and k_i denotes the degree of node i.\n\nNotes: \n\nthis function is intented for use with the expected adjacency matrix of a ::AbstractMaxEntropyModel model. A separate method exists for ::AbstractGraph objects.\nif A is not symmetrical, you have a directed graph, and this will throw an error by default. This can be turned off by setting check_directed=false.\nthe adjacency matrix should be square, if not, this will throw an error by default. This can be turned off by setting check_dimensions=false.\n\nExamples\n\njulia> using Graphs\n\njulia> G = smallgraph(:karate);\n\njulia> A = adjacency_matrix(G);\n\njulia> ANND(A);\n\n\njulia> Gd = SimpleDiGraph(G);\n\njulia> add_vertex!(Gd); add_edge!(Gd, 1, nv(Gd));\n\njulia> Ad = adjacency_matrix(Gd);\n\njulia> ANND(Ad)\nERROR: ArgumentError: The matrix is not symmetrical. Consider using ANND_in or ANND_out instead.\n[...]\n\njulia> ANND(Ad, check_directed=false)[1]\n4.375\n\n\njulia> ANND(rand(2,3))\nERROR: DimensionMismatch: `A` must be a square matrix.\n[...]\n\nSee also: ANND_in, ANND_out, Graphs.degree\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.ANND_out","page":"API","title":"MaxEntropyGraphs.ANND_out","text":"ANNDout(A::T, vs=1:size(A,1); checkdimensions::Bool=true, check_directed::Bool=true) where {T<:AbstractMatrix}\n\nReturn a vector corresponding to the average nearest neighbor outdegree (ANND) all nodes in the graph with adjacency matrix A.  If v is specified, only return the ANND_out for nodes in v. \n\nSee also: ANND_in, ANND\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.ANND_in","page":"API","title":"MaxEntropyGraphs.ANND_in","text":"ANNDin(A::T, vs=1:size(A,1); checkdimensions::Bool=true, check_directed::Bool=true) where {T<:AbstractMatrix}\n\nReturn a vector corresponding to the average nearest neighbor indegree (ANND) all nodes in the graph with adjacency matrix A.  If v is specified, only return the ANND_in for nodes in v. \n\nSee also: ANND_out, ANND\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.wedges","page":"API","title":"MaxEntropyGraphs.wedges","text":"wedges(G::Graphs.SimpleGraph)\nwedges(A::T; check_dimensions::Bool=true, check_directed::Bool=true) where {T<:AbstractMatrix}\nwedges(m::UBCM)\n\nCompute the number of (expected) wedges for an undirected graph. Can be done directly from the graph, based on the adjacency matrix or a UBCM model.\n\nArguments\n\nFor the adjacency matrix A, the following arguments can be passed:\n\ncheck_dimensions: if true, check that A is a square matrix, otherwise throw an error.\ncheck_directed: if true, check that A is symmetrical, otherwise throw an error.\n\nExamples\n\njulia> G = MaxEntropyGraphs.Graphs.smallgraph(:karate);\n\njulia> model = UBCM(G);\n\njulia> solve_model!(model);\n\njulia> set_Ĝ!(model);\n\njulia> (wedges(G), wedges(MaxEntropyGraphs.Graphs.adjacency_matrix(G)), wedges(model))\n(528.0, 528.0, 528.0000011499742)\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.triangles","page":"API","title":"MaxEntropyGraphs.triangles","text":"triangles(G::Graphs.SimpleGraph)\ntriangles(A::T; check_dimensions::Bool=true, check_directed::Bool=true) where {T<:AbstractMatrix}\ntriangles(m::UBCM)\n\nCompute the number of (expected) triangles for an undirected graph. Can be done directly from the graph, based on the adjacency matrix or a UBCM model.\n\nArguments\n\nFor the adjacency matrix A, the following arguments can be passed:\n\ncheck_dimensions: if true, check that A is a square matrix, otherwise throw an error.\ncheck_directed: if true, check that A is symmetrical, otherwise throw an error.\n\nThese checks can be turned off for perfomance reasons.\n\nExamples\n\njulia> G = MaxEntropyGraphs.Graphs.smallgraph(:karate);\n\njulia> model = UBCM(G);\n\njulia> solve_model!(model);\n\njulia> set_Ĝ!(model);\n\njulia> (triangles(G), triangles(MaxEntropyGraphs.Graphs.adjacency_matrix(G)), triangles(model))\n(45, 45.0, 52.849301363026846)\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.squares","page":"API","title":"MaxEntropyGraphs.squares","text":"squares(G::Graphs.SimpleGraph)\nsquares(A::T; check_dimensions::Bool=true, check_directed::Bool=true) where {T<:AbstractMatrix}\nsquares(m::UBCM)\n\nCompute the number of (expected) squares for an undirected graph. Can be done directly from the graph, based on the adjacency matrix or a UBCM model.\n\nNotes:\n\nIn this function, by square, a 'pure' square is understood, without any diagonals inside. This explains the difference with the induced subgraph count, which counts all squares, including those with triangles inside. \n\nArguments\n\nFor the adjacency matrix A, the following arguments can be passed:\n\ncheck_dimensions: if true, check that A is a square matrix, otherwise throw an error.\ncheck_directed: if true, check that A is symmetrical, otherwise throw an error.\n\nThese checks can be turned off for perfomance reasons.\n\nExamples\n\njulia> G = MaxEntropyGraphs.Graphs.smallgraph(:karate);\n\njulia> model = UBCM(G);\n\njulia> solve_model!(model);\n\njulia> set_Ĝ!(model);\n\njulia> (squares(G), squares(MaxEntropyGraphs.Graphs.adjacency_matrix(G)), squares(model))\n(36.0, 36.0, 45.644736823949344)\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.a⭢","page":"API","title":"MaxEntropyGraphs.a⭢","text":"a⭢(A::T, i::Int, j::Int) where T<:AbstractArray\n\nCompute non-recipocrated directed link from i to j and not from j to i.\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.a⭠","page":"API","title":"MaxEntropyGraphs.a⭠","text":"a⭠(A::T, i::Int, j::Int) where T<:AbstractArray\n\nComputed non-recipocrated directed link not from i to j and  from j to i.\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.a⭤","page":"API","title":"MaxEntropyGraphs.a⭤","text":"a⭤(A::T, i::Int, j::Int) where T<:AbstractArray\n\nComputed recipocrated directed link between i and j.\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.a̲","page":"API","title":"MaxEntropyGraphs.a̲","text":"a̲(A::T, i::Int, j::Int) where T<:AbstractArray\n\nCompute absence of link between i and j.\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.M1","page":"API","title":"MaxEntropyGraphs.M1","text":"M1(A::T) where T<:AbstractArray\n\nCount the occurence of motif M1 (Σ_{i≠j≠k} a⭠(i,j) a⭢(j,k) a̲(k,i) ) from the adjacency matrix.\n\n\n\n\n\nM1(m::DBCM)\n\nCount the occurence of motif M1 (Σ_{i≠j≠k} a⭠ (i,j) × a⭢ (j,k) × a̲ (k,i) ) from the DBCM model.\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.M2","page":"API","title":"MaxEntropyGraphs.M2","text":"M2(A::T) where T<:AbstractArray\n\nCount the occurence of motif M2 (Σ_{i≠j≠k} a⭠(i,j) a⭠(j,k) a̲(k,i) ) from the adjacency matrix.\n\n\n\n\n\nM2(m::DBCM)\n\nCount the occurence of motif M2 (Σ_{i≠j≠k} a⭠ (i,j) × a⭠ (j,k) × a̲ (k,i) ) from the DBCM model.\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.M3","page":"API","title":"MaxEntropyGraphs.M3","text":"M3(A::T) where T<:AbstractArray\n\nCount the occurence of motif M3 (Σ_{i≠j≠k} a⭠(i,j) a⭤(j,k) a̲(k,i) ) from the adjacency matrix.\n\n\n\n\n\nM3(m::DBCM)\n\nCount the occurence of motif M3 (Σ_{i≠j≠k} a⭠ (i,j) × a⭤ (j,k) × a̲ (k,i) ) from the DBCM model.\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.M4","page":"API","title":"MaxEntropyGraphs.M4","text":"M4(A::T) where T<:AbstractArray\n\nCount the occurence of motif M4 (Σ_{i≠j≠k} a⭠(i,j) a̲(j,k) a⭢(k,i) ) from the adjacency matrix.\n\n\n\n\n\nM4(m::DBCM)\n\nCount the occurence of motif M4 (Σ_{i≠j≠k} a⭠ (i,j) × a̲ (j,k) × a⭢ (k,i) ) from the DBCM model.\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.M5","page":"API","title":"MaxEntropyGraphs.M5","text":"M5(A::T) where T<:AbstractArray\n\nCount the occurence of motif M5 (Σ_{i≠j≠k} a⭠(i,j) a⭢(j,k) a⭢(k,i) ) from the adjacency matrix.\n\n\n\n\n\nM5(m::DBCM)\n\nCount the occurence of motif M5 (Σ_{i≠j≠k} a⭠ (i,j) × a⭢ (j,k) × a⭢ (k,i) ) from the DBCM model.\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.M6","page":"API","title":"MaxEntropyGraphs.M6","text":"M6(A::T) where T<:AbstractArray\n\nCount the occurence of motif M6 (Σ_{i≠j≠k} a⭠(i,j) a⭤(j,k) a⭢(k,i) ) from the adjacency matrix.\n\n\n\n\n\nM6(m::DBCM)\n\nCount the occurence of motif M6 (Σ_{i≠j≠k} a⭠ (i,j) × a⭤ (j,k) × a⭢ (k,i) ) from the DBCM model.\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.M7","page":"API","title":"MaxEntropyGraphs.M7","text":"M7(A::T) where T<:AbstractArray\n\nCount the occurence of motif M7 (Σ_{i≠j≠k} a⭢(i,j) a⭤(j,k) a̲(k,i) ) from the adjacency matrix.\n\n\n\n\n\nM7(m::DBCM)\n\nCount the occurence of motif M7 (Σ_{i≠j≠k} a⭢ (i,j) × a⭤ (j,k) × a̲ (k,i) ) from the DBCM model.\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.M8","page":"API","title":"MaxEntropyGraphs.M8","text":"M8(A::T) where T<:AbstractArray\n\nCount the occurence of motif M8 (Σ_{i≠j≠k} a⭤(i,j) a⭤(j,k) a̲(k,i) ) from the adjacency matrix.\n\n\n\n\n\nM8(m::DBCM)\n\nCount the occurence of motif M8 (Σ_{i≠j≠k} a⭤ (i,j) × a⭤ (j,k) × a̲ (k,i) ) from the DBCM model.\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.M9","page":"API","title":"MaxEntropyGraphs.M9","text":"M9(A::T) where T<:AbstractArray\n\nCount the occurence of motif M9 (Σ_{i≠j≠k} a⭢(i,j) a⭢(j,k) a⭢(k,i) ) from the adjacency matrix.\n\n\n\n\n\nM9(m::DBCM)\n\nCount the occurence of motif M9 (Σ_{i≠j≠k} a⭢ (i,j) × a⭢ (j,k) × a⭢ (k,i) ) from the DBCM model.\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.M10","page":"API","title":"MaxEntropyGraphs.M10","text":"M10(A::T) where T<:AbstractArray\n\nCount the occurence of motif M10 (Σ_{i≠j≠k} a⭤(i,j) a⭢(j,k) a⭢(k,i) ) from the adjacency matrix.\n\n\n\n\n\nM10(m::DBCM)\n\nCount the occurence of motif M10 (Σ_{i≠j≠k} a⭤ (i,j) × a⭢ (j,k) × a⭢ (k,i) ) from the DBCM model.\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.M11","page":"API","title":"MaxEntropyGraphs.M11","text":"M11(A::T) where T<:AbstractArray\n\nCount the occurence of motif M11 (Σ_{i≠j≠k} a⭤(i,j) a⭠(j,k) a⭢(k,i) ) from the adjacency matrix.\n\n\n\n\n\nM11(m::DBCM)\n\nCount the occurence of motif M11 (Σ_{i≠j≠k} a⭤ (i,j) × a⭠ (j,k) × a⭢ (k,i) ) from the DBCM model.\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.M12","page":"API","title":"MaxEntropyGraphs.M12","text":"M12(A::T) where T<:AbstractArray\n\nCount the occurence of motif M12 (Σ_{i≠j≠k} a⭤(i,j) a⭤(j,k) a⭢(k,i) ) from the adjacency matrix.\n\n\n\n\n\nM12(m::DBCM)\n\nCount the occurence of motif M12 (Σ_{i≠j≠k} a⭤ (i,j) × a⭤ (j,k) × a⭢ (k,i) ) from the DBCM model.\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.M13","page":"API","title":"MaxEntropyGraphs.M13","text":"M13(A::T) where T<:AbstractArray\n\nCount the occurence of motif M13 (Σ_{i≠j≠k} a⭤(i,j) a⭤(j,k) a⭤(k,i) ) from the adjacency matrix.\n\n\n\n\n\nM13(m::DBCM)\n\nCount the occurence of motif M13 (Σ_{i≠j≠k} a⭤ (i,j) × a⭤ (j,k) × a⭤ (k,i) ) from the DBCM model.\n\n\n\n\n\n","category":"function"},{"location":"API/#UBCM","page":"API","title":"UBCM","text":"","category":"section"},{"location":"API/","page":"API","title":"API","text":"MaxEntropyGraphs.UBCM\nUBCM(::T) where {T}\nMaxEntropyGraphs.solve_model!(::UBCM)\nMaxEntropyGraphs.initial_guess(::UBCM)\nBase.rand(::UBCM)\nBase.rand(::UBCM,::Int)\nMaxEntropyGraphs.AIC(::UBCM)\nMaxEntropyGraphs.AICc(::UBCM)\nMaxEntropyGraphs.BIC(::UBCM)\nBase.length(::UBCM)\nMaxEntropyGraphs.L_UBCM_reduced\nMaxEntropyGraphs.∇L_UBCM_reduced!\nMaxEntropyGraphs.∇L_UBCM_reduced_minus!\nMaxEntropyGraphs.UBCM_reduced_iter!\nMaxEntropyGraphs.set_xᵣ!(::UBCM)\nMaxEntropyGraphs.Ĝ(::UBCM)\nMaxEntropyGraphs.set_Ĝ!(::UBCM)\nMaxEntropyGraphs.σˣ(::UBCM)\nMaxEntropyGraphs.set_σ!(::UBCM)\nMaxEntropyGraphs.precision(::UBCM)\nMaxEntropyGraphs.A(::UBCM,::Int64,::Int64)\nMaxEntropyGraphs.f_UBCM(::UBCM)\nMaxEntropyGraphs.σₓ(::UBCM, ::Function)","category":"page"},{"location":"API/#MaxEntropyGraphs.UBCM","page":"API","title":"MaxEntropyGraphs.UBCM","text":"UBCM\n\nMaximum entropy model for the Undirected Binary Configuration Model (UBCM). \n\nThe object holds the maximum likelihood parameters of the model (θ) and optionally the expected adjacency matrix (G),  and the variance for the elements of the adjacency matrix (σ). All settings and other metadata are stored in the status field.\n\n\n\n\n\n","category":"type"},{"location":"API/#MaxEntropyGraphs.UBCM-Tuple{T} where T","page":"API","title":"MaxEntropyGraphs.UBCM","text":"UBCM(G::T; d::Vector=Graphs.degree(G), precision::N=Float64, kwargs...) where {T<:Graphs.AbstractGraph, N<:Real}\nUBCM(d::Vector{T}, precision::Type{<:AbstractFloat}=Float64, kwargs...)\n\nConstructor function for the UBCM type. \n\nBy default and dependng on the graph type T, the definition of degree from Graphs.jl is applied.  If you want to use a different definition of degree, you can pass a vector of degrees as the second argument. If you want to generate a model directly from a degree sequence without an underlying graph, you can simply pass the degree sequence as an argument. If you want to work from an adjacency matrix, or edge list, you can use the graph constructors from the JuliaGraphs ecosystem.\n\nExamples\n\n# generating a model from a graph\njulia> G = MaxEntropyGraphs.Graphs.SimpleGraphs.smallgraph(:karate)\n{34, 78} undirected simple Int64 graph\njulia> model = UBCM(G)\nUBCM{Graphs.SimpleGraphs.SimpleGraph{Int64}, Float64} (34 vertices, 11 unique degrees, 0.32 compression ratio)\n\n# generating a model directly from a degree sequence\njulia> model = UBCM(d=[4;3;3;3;2])\nUBCM{Nothing, Float64} (5 vertices, 3 unique degrees, 0.60 compression ratio)\n\n# generating a model directly from a degree sequence with a different precision\njulia> model = UBCM(d=[4;3;3;3;2], precision=Float16)\nUBCM{Nothing, Float16} (5 vertices, 3 unique degrees, 0.60 compression ratio)\n\n# generating a model from an adjacency matrix\njulia> A = [0 1 1;1 0 0;1 0 0];\n\njulia> G = MaxEntropyGraphs.Graphs.SimpleGraph(A)\n{3, 2} undirected simple Int64 graph\njulia> model = UBCM(G)\nUBCM{Graphs.SimpleGraphs.SimpleGraph{Int64}, Float64} (3 vertices, 2 unique degrees, 0.67 compression ratio)\n\n# generating a model from an edge list\njulia> E = [(1,2),(1,3),(2,3)];\n\njulia> edgelist = [MaxEntropyGraphs.Graphs.Edge(x,y) for (x,y) in E];\n\njulia> G = MaxEntropyGraphs.Graphs.SimpleGraphFromIterator(edgelist)\n{3, 3} undirected simple Int64 graph\njulia> model = UBCM(G)\nUBCM{Graphs.SimpleGraphs.SimpleGraph{Int64}, Float64} (3 vertices, 1 unique degrees, 0.33 compression ratio)\n\nSee also Graphs.degree, SimpleWeightedGraphs.inneighbors.\n\n\n\n\n\n","category":"method"},{"location":"API/#MaxEntropyGraphs.solve_model!-Tuple{UBCM}","page":"API","title":"MaxEntropyGraphs.solve_model!","text":"solve_model!(m::UBCM; kwargs...)\n\nCompute the likelihood maximising parameters of the UBCM model m. \n\nArguments\n\nmethod::Symbol: solution method to use, can be :fixedpoint (default), or :NelderMead, :BFGS, :LBFGS and :Newton.\ninitial::Symbol: initial guess for the parameters Theta, can be :degrees, :degreesminor, :random, :uniform, or :chunglu.\nmaxiters::Int: maximum number of iterations for the solver (defaults to 1000). \nverbose::Bool: set to show log messages (defaults to false).\nftol::Real: function tolerance for convergence with the fixedpoint method (defaults to 1e-8).\nabstol::Union{Number, Nothing}: absolute function tolerance for convergence with the other methods (defaults to nothing).\nreltol::Union{Number, Nothing}: relative function tolerance for convergence with the other methods (defaults to nothing).\nAD_method::Symbol: autodiff method to use, can be any of :AutoZygote, :AutoReverseDiff, :AutoForwardDiff and :AutoFiniteDiff. Performance depends on the size of the problem (defaults to :AutoZygote),\nanalytical_gradient::Bool: set the use the analytical gradient instead of the one generated with autodiff (defaults to false)\n\nExamples\n\n# default use\njulia> model = UBCM(MaxEntropyGraphs.Graphs.SimpleGraphs.smallgraph(:karate));\n\njulia> solve_model!(model);\n\n\n# using analytical gradient and degrees minor initial guess\njulia> solve_model!(model, method=:BFGS, analytical_gradient=true, initial=:degrees_minor)\n(UBCM{Graphs.SimpleGraphs.SimpleGraph{Int64}, Float64} (34 vertices, 11 unique degrees, 0.32 compression ratio), retcode: Success\nu: [2.851659905903854, 2.053008374573552, 1.5432639513870743, 1.152360118212239, 0.8271267490690292, 0.5445045274064909, -0.1398726818076551, -0.3293252270659469, -0.6706207459338859, -1.2685575582149227, -1.410096540372487]\nFinal objective value:     168.68325136302835\n)\n\n\nSee also: initial_guess, ∇L_UBCM_reduced!\n\n\n\n\n\n","category":"method"},{"location":"API/#MaxEntropyGraphs.initial_guess-Tuple{UBCM}","page":"API","title":"MaxEntropyGraphs.initial_guess","text":"initial_guess(m::UBCM, method::Symbol=:degrees)\n\nCompute an initial guess for the maximum likelihood parameters of the UBCM model m using the method method.\n\nThe methods available are: \n\n:degrees (default): the initial guess is computed using the degrees of the graph, i.e. theta_i = -log(d_i) \n:degrees_minor: the initial guess is computed using the degrees of the graph and the number of edges, i.e. theta_i = -log(d_i(sqrtE + 1))\n:random: the initial guess is computed using random values between 0 and 1, i.e. theta_i = -log(r_i) where r_i sim U(01)\n:uniform: the initial guess is uniformily set to 0.5, i.e. theta_i = -log(05)\n:chung_lu: the initial guess is computed using the degrees of the graph and the number of edges, i.e. theta_i = -log(d_i(2E))\n\nExamples\n\njulia> model = UBCM(MaxEntropyGraphs.Graphs.SimpleGraphs.smallgraph(:karate));\n\njulia> initial_guess(model, method=:random);\n\njulia> initial_guess(model, method=:uniform);\n\njulia> initial_guess(model, method=:degrees_minor);\n\njulia> initial_guess(model, method=:chung_lu);\n\njulia> initial_guess(model)\n11-element Vector{Float64}:\n -0.0\n -0.6931471805599453\n -1.0986122886681098\n -1.3862943611198906\n -1.6094379124341003\n -1.791759469228055\n -2.1972245773362196\n -2.302585092994046\n -2.4849066497880004\n -2.772588722239781\n -2.833213344056216\n\n\n\n\n\n\n","category":"method"},{"location":"API/#Base.rand-Tuple{UBCM}","page":"API","title":"Base.rand","text":"rand(m::UBCM; precomputed=false)\n\nGenerate a random graph from the UBCM model m.\n\nArguments\n\nprecomputed::Bool: if true, the precomputed expected adjacency matrix (m.Ĝ) is used to generate the random graph, otherwise the maximum likelihood parameters are used to generate the random graph on the fly. For larger networks, it is  recommended to not precompute the expected adjacency matrix to limit memory pressure.\n\nExamples\n\njulia> model = UBCM(MaxEntropyGraphs.Graphs.SimpleGraphs.smallgraph(:karate)); # generate a UBCM model from the karate club network\n\njulia> solve_model!(model); # compute the maximum likelihood parameters\n\njulia> sample = rand(model); # sample a random graph\n\njulia> typeof(sample)\nGraphs.SimpleGraphs.SimpleGraph{Int64}\n\n\n\n\n\n","category":"method"},{"location":"API/#Base.rand-Tuple{UBCM, Int64}","page":"API","title":"Base.rand","text":"rand(m::UBCM, n::Int; precomputed=false)\n\nGenerate n random graphs from the UBCM model m. If multithreading is available, the graphs are generated in parallel.\n\nArguments\n\nprecomputed::Bool: if true, the precomputed expected adjacency matrix (m.Ĝ) is used to generate the random graph, otherwise the maximum likelihood parameters are used to generate the random graph on the fly. For larger networks, it is  recommended to not precompute the expected adjacency matrix to limit memory pressure.\n\nExamples\n\njulia> model = UBCM(MaxEntropyGraphs.Graphs.SimpleGraphs.smallgraph(:karate)); # generate a UBCM model from the karate club network\n\njulia> solve_model!(model); # compute the maximum likelihood parameters\n\njulia> sample = rand(model, 10); # sample a set of random graphs\n\njulia> typeof(sample)\nVector{SimpleGraph{Int64}} (alias for Array{Graphs.SimpleGraphs.SimpleGraph{Int64}, 1})\n\n\n\n\n\n","category":"method"},{"location":"API/#MaxEntropyGraphs.AIC-Tuple{UBCM}","page":"API","title":"MaxEntropyGraphs.AIC","text":"AIC(m::UBCM)\n\nCompute the Akaike Information Criterion (AIC) for the UBCM model m. The parameters of the models most be computed beforehand.  If the number of empirical observations becomes too small with respect to the number of parameters, you will get a warning. In  that case, the corrected AIC (AICc) should be used instead.\n\nExamples\n\njulia> model = UBCM(MaxEntropyGraphs.Graphs.SimpleGraphs.smallgraph(:karate));\n\njulia> solve_model!(model);\n\njulia> AIC(model);\n[...]\n\n\nSee also AICc, L_UBCM_reduced.\n\n\n\n\n\n","category":"method"},{"location":"API/#MaxEntropyGraphs.AICc-Tuple{UBCM}","page":"API","title":"MaxEntropyGraphs.AICc","text":"AICc(m::UBCM)\n\nCompute the corrected Akaike Information Criterion (AICc) for the UBCM model m. The parameters of the models most be computed beforehand. \n\nExamples\n\njulia> model = UBCM(MaxEntropyGraphs.Graphs.SimpleGraphs.smallgraph(:karate));\n\njulia> solve_model!(model);\n\njulia> AICc(model)\n409.891217554954\n\n\nSee also AIC, L_UBCM_reduced.\n\n\n\n\n\n","category":"method"},{"location":"API/#MaxEntropyGraphs.BIC-Tuple{UBCM}","page":"API","title":"MaxEntropyGraphs.BIC","text":"BIC(m::UBCM)\n\nCompute the Bayesian Information Criterion (BIC) for the UBCM model m. The parameters of the models most be computed beforehand.  BIC is believed to be more restrictive than AIC, as the former favors models with a lower number of parameters than those favored by the latter.\n\nExamples\n\njulia> model = UBCM(MaxEntropyGraphs.Graphs.SimpleGraphs.smallgraph(:karate));\n\njulia> solve_model!(model);\n\njulia> BIC(model)\n552.5770135138283\n\n\nSee also AIC, L_UBCM_reduced.\n\n\n\n\n\n","category":"method"},{"location":"API/#Base.length-Tuple{UBCM}","page":"API","title":"Base.length","text":"Return the reduced number of nodes in the UBCM network\n\n\n\n\n\n","category":"method"},{"location":"API/#MaxEntropyGraphs.L_UBCM_reduced","page":"API","title":"MaxEntropyGraphs.L_UBCM_reduced","text":"L_UBCM_reduced(θ::Vector, K::Vector, F::Vector)\n\nCompute the log-likelihood of the reduced UBCM model using the exponential formulation in order to maintain convexity.\n\nArguments\n\nθ: the maximum likelihood parameters of the model\nK: the reduced degree sequence\nF: the frequency of each degree in the degree sequence\n\nThe function returns the log-likelihood of the reduced model. For the optimisation, this function will be used to generate an anonymous function associated with a specific model.\n\nExamples\n\n# Generic use:\njulia> θ = [1.0, 2.0, 3.0, 4.0, 5.0];\n\njulia> K = [1, 2, 3, 4, 5];\n\njulia> F = [1, 2, 3, 4, 5];\n\njulia> L_UBCM_reduced(θ, K, F)\n-225.3065566905141\n\n\n\n\n\nL_UBCM_reduced(m::UBCM)\n\nReturn the log-likelihood of the UBCM model m based on the computed maximum likelihood parameters.\n\nExamples\n\n# Use with UBCM model:\njulia> G = MaxEntropyGraphs.Graphs.SimpleGraphs.smallgraph(:karate);\n\njulia> model = UBCM(G);\n\njulia> solve_model!(model);\n\njulia> L_UBCM_reduced(model)\n-168.68325136302832\n\nSee also L_UBCM_reduced(::Vector, ::Vector, ::Vector)\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.∇L_UBCM_reduced!","page":"API","title":"MaxEntropyGraphs.∇L_UBCM_reduced!","text":"∇L_UBCM_reduced!(∇L::Vector, θ::Vector, K::Vector, F::Vector, x::Vector)\n\nCompute the gradient of the log-likelihood of the reduced UBCM model using the exponential formulation (to maintain convexity).\n\nFor the optimisation, this function will be used togenerate an anonymous function associated with a specific model.  The gradient is non-allocating and will update pre-allocated vectors (∇L and x) for speed. \n\nArguments\n\n∇L: the gradient of the log-likelihood of the reduced model\nθ: the maximum likelihood parameters of the model\nK: the reduced degree sequence\nF: the frequency of each degree in the degree sequence\nx: the exponentiated maximum likelihood parameters of the model ( xᵢ = exp(-θᵢ) )\n\nExamples\n\n# Explicit use with UBCM model:\njulia> G = MaxEntropyGraphs.Graphs.SimpleGraphs.smallgraph(:karate);\n\njulia> model = UBCM(G);\n\njulia> ∇L = zeros(Real, length(model.θᵣ));\n\njulia> x  = zeros(Real, length(model.θᵣ));\n\njulia> ∇model_fun! = θ -> ∇L_UBCM_reduced!(∇L, θ, model.dᵣ, model.f, x);\n\njulia> ∇model_fun!(model.θᵣ);\n\n\n# Use within optimisation.jl framework:\njulia> model = UBCM(MaxEntropyGraphs.Graphs.SimpleGraphs.smallgraph(:karate));\n\njulia> fun =  (θ, p) ->  - L_UBCM_reduced(θ, model.dᵣ, model.f);\n\njulia> x  = zeros(Real, length(model.θᵣ)); # initialise gradient buffer\n\njulia> ∇fun! = (∇L, θ, p) -> ∇L_UBCM_reduced!(∇L, θ, model.dᵣ, model.f, x); # define gradient\n\njulia> θ₀ = initial_guess(model); # initial condition\n\njulia> foo = MaxEntropyGraphs.Optimization.OptimizationFunction(fun, grad=∇fun!); # define target function \n\njulia> prob  = MaxEntropyGraphs.Optimization.OptimizationProblem(foo, θ₀); # define the optimisation problem\n\njulia> method = MaxEntropyGraphs.OptimizationOptimJL.LBFGS(); # set the optimisation method\n\njulia> MaxEntropyGraphs.Optimization.solve(prob, method); # solve it\n\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.∇L_UBCM_reduced_minus!","page":"API","title":"MaxEntropyGraphs.∇L_UBCM_reduced_minus!","text":"∇L_UBCM_reduced_minus!(args...)\n\nCompute minus the gradient of the log-likelihood of the reduced UBCM model using the exponential formulation in order to maintain convexity. Used for optimisation in a non-allocating manner.\n\nSee also ∇L_UBCM_reduced!\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.UBCM_reduced_iter!","page":"API","title":"MaxEntropyGraphs.UBCM_reduced_iter!","text":"UBCM_reduced_iter!(θ, K, F, x, G)\n\nComputer the next fixed-point iteration for the UBCM model using the exponential formulation in order to maintain convexity. The function will update pre-allocated vectors (G and x) for speed.\n\nArguments\n\nθ: the maximum likelihood parameters of the model\nK: the reduced degree sequence\nF: the frequency of each degree in the degree sequence\nx: the exponentiated maximum likelihood parameters of the model ( xᵢ = exp(-θᵢ) ) (pre-allocated)\nG: the next fixed-point iteration for the UBCM model (pre-allocated)\n\nExamples\n\njulia> model = UBCM(MaxEntropyGraphs.Graphs.SimpleGraphs.smallgraph(:karate));\n\njulia> G = zeros(eltype(model.θᵣ), length(model.θᵣ));\n\njulia> x = zeros(eltype(model.θᵣ), length(model.θᵣ));\n\njulia> UBCM_FP! = θ -> UBCM_reduced_iter!(θ, model.dᵣ, model.f, x, G);\n\njulia> UBCM_FP!(initial_guess(model));\n\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.set_xᵣ!-Tuple{UBCM}","page":"API","title":"MaxEntropyGraphs.set_xᵣ!","text":"set_xᵣ!(m::UBCM)\n\nSet the value of xᵣ to exp(-θᵣ) for the UBCM model m\n\n\n\n\n\n","category":"method"},{"location":"API/#MaxEntropyGraphs.Ĝ-Tuple{UBCM}","page":"API","title":"MaxEntropyGraphs.Ĝ","text":"Ĝ(m::UBCM)\n\nCompute the expected adjacency matrix for the UBCM model m\n\n\n\n\n\n","category":"method"},{"location":"API/#MaxEntropyGraphs.set_Ĝ!-Tuple{UBCM}","page":"API","title":"MaxEntropyGraphs.set_Ĝ!","text":"set_Ĝ!(m::UBCM)\n\nSet the expected adjacency matrix for the UBCM model m\n\n\n\n\n\n","category":"method"},{"location":"API/#MaxEntropyGraphs.σˣ-Tuple{UBCM}","page":"API","title":"MaxEntropyGraphs.σˣ","text":"σˣ(m::UBCM{T,N}) where {T,N}\n\nCompute the standard deviation for the elements of the adjacency matrix for the UBCM model m.\n\nNote: read as \"sigma star\"\n\n\n\n\n\n","category":"method"},{"location":"API/#MaxEntropyGraphs.set_σ!-Tuple{UBCM}","page":"API","title":"MaxEntropyGraphs.set_σ!","text":"set_σ!(m::UBCM)\n\nSet the standard deviation for the elements of the adjacency matrix for the UBCM model m\n\n\n\n\n\n","category":"method"},{"location":"API/#Base.precision-Tuple{UBCM}","page":"API","title":"Base.precision","text":"precision(m::UBCM)\n\nDetermine the compute precision of the UBCM model m.\n\nExamples\n\njulia> model = UBCM(MaxEntropyGraphs.Graphs.SimpleGraphs.smallgraph(:karate));\n\njulia> MaxEntropyGraphs.precision(model)\nFloat64\n\njulia> model = UBCM(MaxEntropyGraphs.Graphs.SimpleGraphs.smallgraph(:karate), precision=Float32);\n\njulia> MaxEntropyGraphs.precision(model)\nFloat32\n\n\n\n\n\n","category":"method"},{"location":"API/#MaxEntropyGraphs.A-Tuple{UBCM, Int64, Int64}","page":"API","title":"MaxEntropyGraphs.A","text":"A(m::UBCM,i::Int,j::Int)\n\nReturn the expected value of the adjacency matrix for the UBCM model m at the node pair (i,j).\n\n❗ For perfomance reasons, the function does not check:\n\nif the node pair is valid.\nif the parameters of the model have been computed.\n\n\n\n\n\n","category":"method"},{"location":"API/#MaxEntropyGraphs.f_UBCM-Tuple{UBCM}","page":"API","title":"MaxEntropyGraphs.f_UBCM","text":"f_UBCM(x::T)\n\nHelper function for the UBCM model to compute the expected value of the adjacency matrix. The function computes the expression x / (1 + x). As an argument you need to pass the product of the maximum likelihood parameters xᵣ[i] * xᵣ[j] from a UBCM model.\n\n\n\n\n\n","category":"method"},{"location":"API/#MaxEntropyGraphs.σₓ-Tuple{UBCM, Function}","page":"API","title":"MaxEntropyGraphs.σₓ","text":"σₓ(m::UBCM, X::function)\n\nCompute the standard deviation of metric X for the UBCM model m. \n\nThis requires that both the expected values (m.Ĝ) and standard deviations (m.σ) are computed for m.\n\n\n\n\n\n","category":"method"},{"location":"API/#DBCM","page":"API","title":"DBCM","text":"","category":"section"},{"location":"API/","page":"API","title":"API","text":"MaxEntropyGraphs.DBCM\nDBCM(::T) where {T}\nMaxEntropyGraphs.solve_model!(::DBCM)\nMaxEntropyGraphs.initial_guess(::DBCM)\nBase.rand(::DBCM)\nBase.rand(::DBCM,::Int)\nMaxEntropyGraphs.AIC(::DBCM)\nMaxEntropyGraphs.AICc(::DBCM)\nMaxEntropyGraphs.BIC(::DBCM)\nBase.length(::DBCM)\nMaxEntropyGraphs.L_DBCM_reduced\nMaxEntropyGraphs.∇L_DBCM_reduced!\nMaxEntropyGraphs.∇L_DBCM_reduced_minus!\nMaxEntropyGraphs.DBCM_reduced_iter!\nMaxEntropyGraphs.set_xᵣ!(::DBCM)\nMaxEntropyGraphs.set_yᵣ!(::DBCM)\nMaxEntropyGraphs.Ĝ(::DBCM)\nMaxEntropyGraphs.set_Ĝ!(::DBCM)\nMaxEntropyGraphs.σˣ(::DBCM)\nMaxEntropyGraphs.set_σ!(::DBCM)\nMaxEntropyGraphs.precision(::DBCM)\nMaxEntropyGraphs.A(::DBCM,::Int64,::Int64)\nMaxEntropyGraphs.f_DBCM(::DBCM)\nMaxEntropyGraphs.σₓ(::DBCM, ::Function)","category":"page"},{"location":"API/#MaxEntropyGraphs.DBCM","page":"API","title":"MaxEntropyGraphs.DBCM","text":"DBCM\n\nMaximum entropy model for the Directed Binary Configuration Model (UBCM).\n\nThe object holds the maximum likelihood parameters of the model (θ) and optionally the expected adjacency matrix (G),  and the variance for the elements of the adjacency matrix (σ). All settings and other metadata are stored in the status field.\n\n\n\n\n\n","category":"type"},{"location":"API/#MaxEntropyGraphs.DBCM-Tuple{T} where T","page":"API","title":"MaxEntropyGraphs.DBCM","text":"DBCM(G::T; precision::N=Float64, kwargs...) where {T<:Graphs.AbstractGraph, N<:Real}\nDBCM(;d_out::Vector{T}, d_in::Vector{T}, precision::Type{<:AbstractFloat}=Float64, kwargs...)\n\nConstructor function for the DBCM type. \n\nBy default and dependng on the graph type T, the definition of in- and outdegree from Graphsjl is applied.  If you want to use a different definition of degrees, you can pass vectors of degrees sequences as keyword arguments (d_out, d_in). If you want to generate a model directly from degree sequences without an underlying graph, you can simply pass the degree sequences as arguments (d_out, d_in). If you want to work from an adjacency matrix, or edge list, you can use the graph constructors from the JuliaGraphs ecosystem.\n\nExamples\n\n# generating a model from a graph\njulia> G = MaxEntropyGraphs.Graphs.SimpleDiGraph(rhesus_macaques())\n{16, 111} directed simple Int64 graph\njulia> model = DBCM(G)\nDBCM{Graphs.SimpleGraphs.SimpleDiGraph{Int64}, Float64} (16 vertices, 15 unique degree pairs, 0.94 compression ratio)\n\n# generating a model directly from a degree sequence\njulia> model = DBCM(d_out=MaxEntropyGraphs.Graphs.outdegree(G), d_in=MaxEntropyGraphs.Graphs.indegree(G))\nDBCM{Nothing, Float64} (16 vertices, 15 unique degree pairs, 0.94 compression ratio)\n\n# generating a model directly from a degree sequence with a different precision\njulia>  model = DBCM(d_out=MaxEntropyGraphs.Graphs.outdegree(G), d_in=MaxEntropyGraphs.Graphs.indegree(G), precision=Float32)\nDBCM{Nothing, Float32} (16 vertices, 15 unique degree pairs, 0.94 compression ratio)\n\n# generating a model from an adjacency matrix\njulia> A = [0 1 1;1 0 0;1 1 0];\n\njulia> G = MaxEntropyGraphs.Graphs.SimpleDiGraph(A)\n{3, 5} directed simple Int64 graph\njulia> model = DBCM(G)\nDBCM{Graphs.SimpleGraphs.SimpleDiGraph{Int64}, Float64} (3 vertices, 3 unique degree pairs, 1.00 compression ratio)\n\n# generating a model from an edge list\njulia> E = [(1,2),(1,3),(2,3)];\n\njulia> edgelist = [MaxEntropyGraphs.Graphs.Edge(x,y) for (x,y) in E];\n\njulia> G = MaxEntropyGraphs.Graphs.SimpleDiGraphFromIterator(edgelist)\n{3, 3} directed simple Int64 graph\njulia> model = DBCM(G)\nDBCM{Graphs.SimpleGraphs.SimpleDiGraph{Int64}, Float64} (3 vertices, 3 unique degree pairs, 1.00 compression ratio)\n\n\nSee also Graphs.outdegree, Graphs.indegree.\n\n\n\n\n\n","category":"method"},{"location":"API/#MaxEntropyGraphs.solve_model!-Tuple{DBCM}","page":"API","title":"MaxEntropyGraphs.solve_model!","text":"solve_model!(m::DBCM)\n\nCompute the likelihood maximising parameters of the DBCM model m. \n\nArguments\n\nmethod::Symbol: solution method to use, can be :fixedpoint (default), or :NelderMead, :BFGS, :LBFGS and :Newton.\ninitial::Symbol: initial guess for the parameters Theta, can be :degrees (default), :degreesminor, :random, :uniform, or :chunglu.\nmaxiters::Int: maximum number of iterations for the solver (defaults to 1000). \nverbose::Bool: set to show log messages (defaults to false).\nftol::Real: function tolerance for convergence with the fixedpoint method (defaults to 1e-8).\nabstol::Union{Number, Nothing}: absolute function tolerance for convergence with the other methods (defaults to nothing).\nreltol::Union{Number, Nothing}: relative function tolerance for convergence with the other methods (defaults to nothing).\nAD_method::Symbol: autodiff method to use, can be any of :AutoZygote, :AutoReverseDiff, :AutoForwardDiff and :AutoFiniteDiff. Performance depends on the size of the problem (defaults to :AutoZygote),\nanalytical_gradient::Bool: set the use the analytical gradient instead of the one generated with autodiff (defaults to false)\n\nExamples\n\n# default use\njulia> model = DBCM(MaxEntropyGraphs.Graphs.SimpleDiGraph(rhesus_macaques()));\n\njulia> solve_model!(model);\n\n\n# using analytical gradient and degrees minor initial guess\njulia> solve_model!(model, method=:BFGS, analytical_gradient=true, initial=:degrees_minor)\n(DBCM{Graphs.SimpleGraphs.SimpleDiGraph{Int64}, Float64} (16 vertices, 15 unique degree pairs, 0.94 compression ratio), retcode: Success\nu: [3.118482950362848, 2.2567400402511617, 2.2467332710940333, 0.8596258292464105, 0.4957550197436504, 0.3427782029923598, 0.126564995232929, -0.3127732185244699, -0.3967757456352901, -0.43450987676209596  …  -0.5626916621021604, 1.223396713832784, 0.10977479732876981, -1.0367565290851806, -2.0427364999923148, -0.650376357149203, -1.5165614611776657, 0.7532475835319463, 0.39856890694767605, -0.6704522097652438]\nFinal objective value:     120.15942408828177\n)\n\n\n\n\n\n\n","category":"method"},{"location":"API/#MaxEntropyGraphs.initial_guess-Tuple{DBCM}","page":"API","title":"MaxEntropyGraphs.initial_guess","text":"initial_guess(m::DBCM, method::Symbol=:degrees)\n\nCompute an initial guess for the maximum likelihood parameters of the DBCM model m using the method method.\n\nThe methods available are: \n\n:degrees (default): the initial guess is computed using the degrees of the graph, i.e. theta = -log(d_out) -log(d_in) \n:degrees_minor: the initial guess is computed using the degrees of the graph and the number of edges, i.e. theta = -log(d_out(sqrtE + 1)) -log(d_in(sqrtE + 1) )\n:random: the initial guess is computed using random values between 0 and 1, i.e. theta_i = -log(r_i) where r_i sim U(01)\n:uniform: the initial guess is uniformily set to 0.5, i.e. theta_i = -log(05)\n:chung_lu: the initial guess is computed using the degrees of the graph and the number of edges, i.e. theta = -log(d_out(2E)) -log(d_in(2E))\n\nExamples\n\njulia> model = DBCM(MaxEntropyGraphs.Graphs.SimpleDiGraph(rhesus_macaques()));\n\njulia> initial_guess(model, method=:random);\n\njulia> initial_guess(model, method=:uniform);\n\njulia> initial_guess(model, method=:degrees_minor);\n\njulia> initial_guess(model, method=:chung_lu);\n\njulia> initial_guess(model);\n\n\n\n\n\n\n","category":"method"},{"location":"API/#Base.rand-Tuple{DBCM}","page":"API","title":"Base.rand","text":"rand(m::DBCM; precomputed=false)\n\nGenerate a random graph from the DBCM model m.\n\nArguments:\n\nprecomputed::Bool: if true, the precomputed expected adjacency matrix (m.Ĝ) is used to generate the random graph, otherwise the maximum likelihood parameters are used to generate the random graph on the fly. For larger networks, it is  recommended to not precompute the expected adjacency matrix to limit memory pressure.\n\nExamples\n\n# generate a DBCM model macaques network\njulia> G = MaxEntropyGraphs.Graphs.SimpleDiGraph(rhesus_macaques());\n\njulia> model = DBCM(G); \n\njulia> solve_model!(model); # compute the maximum likelihood parameters\n\njulia> typeof(rand(model))\nGraphs.SimpleGraphs.SimpleDiGraph{Int64}\n\n\n\n\n\n\n","category":"method"},{"location":"API/#Base.rand-Tuple{DBCM, Int64}","page":"API","title":"Base.rand","text":"rand(m::DBCM, n::Int; precomputed=false)\n\nGenerate n random graphs from the DBCM model m. If multithreading is available, the graphs are generated in parallel.\n\nArguments\n\nprecomputed::Bool: if true, the precomputed expected adjacency matrix (m.Ĝ) is used to generate the random graph, otherwise the maximum likelihood parameters are used to generate the random graph on the fly. For larger networks, it is  recommended to not precompute the expected adjacency matrix to limit memory pressure.\n\nExamples\n\nExamples\n\n# generate a DBCM model macaques network\njulia> G = MaxEntropyGraphs.Graphs.SimpleDiGraph(rhesus_macaques());\n\njulia> model = DBCM(G); \n\njulia> solve_model!(model); # compute the maximum likelihood parameters\n\njulia> typeof(rand(model, 10))\nVector{SimpleDiGraph{Int64}} (alias for Array{Graphs.SimpleGraphs.SimpleDiGraph{Int64}, 1})\n\n\n\n\n\n\n","category":"method"},{"location":"API/#MaxEntropyGraphs.AIC-Tuple{DBCM}","page":"API","title":"MaxEntropyGraphs.AIC","text":"AIC(m::DBCM)\n\nCompute the Akaike Information Criterion (AIC) for the DBCM model m. The parameters of the models most be computed beforehand.  If the number of empirical observations becomes too small with respect to the number of parameters, you will get a warning. In  that case, the corrected AIC (AICc) should be used instead.\n\nExamples\n\njulia> model = DBCM(MaxEntropyGraphs.Graphs.SimpleDiGraph(rhesus_macaques()));\n\njulia> solve_model!(model);\n\njulia> AIC(model);\n┌ Warning: The number of observations is small with respect to the number of parameters (n/k < 40). Consider using the corrected AIC (AICc) instead.\n[...]\n\n\nSee also AICc, L_DBCM_reduced.\n\n\n\n\n\n","category":"method"},{"location":"API/#MaxEntropyGraphs.AICc-Tuple{DBCM}","page":"API","title":"MaxEntropyGraphs.AICc","text":"AICc(m::DBCM)\n\nCompute the corrected Akaike Information Criterion (AICc) for the DBCM model m. The parameters of the models most be computed beforehand. \n\nExamples\n\njulia> model = DBCM(MaxEntropyGraphs.Graphs.SimpleDiGraph(rhesus_macaques()));\n\njulia> solve_model!(model);\n\njulia> AICc(model)\n314.5217467272881\n\n\nSee also AIC, L_DBCM_reduced.\n\n\n\n\n\n","category":"method"},{"location":"API/#MaxEntropyGraphs.BIC-Tuple{DBCM}","page":"API","title":"MaxEntropyGraphs.BIC","text":"BIC(m::DBCM)\n\nCompute the Bayesian Information Criterion (BIC) for the DBCM model m. The parameters of the models most be computed beforehand.  BIC is believed to be more restrictive than AIC, as the former favors models with a lower number of parameters than those favored by the latter.\n\nExamples\n\njulia> model = DBCM(MaxEntropyGraphs.Graphs.SimpleDiGraph(rhesus_macaques()));\n\njulia> solve_model!(model);\n\njulia> BIC(model)\n415.69929372350714\n\n\nSee also AIC, L_DBCM_reduced.\n\n\n\n\n\n","category":"method"},{"location":"API/#Base.length-Tuple{DBCM}","page":"API","title":"Base.length","text":"Return the reduced number of nodes in the UBCM network\n\n\n\n\n\n","category":"method"},{"location":"API/#MaxEntropyGraphs.L_DBCM_reduced","page":"API","title":"MaxEntropyGraphs.L_DBCM_reduced","text":"L_DBCM_reduced(θ::Vector, k_out::Vector, k_in::Vector, F::Vector, nz_out::Vector, nz_in::Vector, n::Int=length(k_out))\n\nCompute the log-likelihood of the reduced DBCM model using the exponential formulation in order to maintain convexity.\n\nArguments\n\n- `θ`: the maximum likelihood parameters of the model ([α; β])\n- `k_out`: the reduced outdegree sequence\n- `k_in`: the reduced indegree sequence\n- `F`: the frequency of each pair in the degree sequence\n- `nz_out`: the indices of non-zero elements in the reduced outdegree sequence\n- `nz_in`: the indices of non-zero elements in the reduced indegree sequence\n- `n`: the number of nodes in the reduced model\n\nThe function returns the log-likelihood of the reduced model. For the optimisation, this function will be used to generate an anonymous function associated with a specific model.\n\nExamples\n\n# Generic use:\njulia> k_out  = [1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5];\n\njulia> k_in   = [2, 3, 4, 1, 3, 5, 2, 4, 1, 2, 4, 0, 4];\n\njulia> F      = [2, 2, 1, 1, 1, 2, 3, 1, 1, 2, 2, 1, 1];\n\njulia> θ      = collect(range(0.1, step=0.1, length=length(k_out)));\n\njulia> nz_out = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13];\n\njulia> nz_in  = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13];\n\njulia> n      = length(k_out);\n\njulia> L_DBCM_reduced(θ, k_out, k_in, F, nz_out, nz_in, n)\n-200.48153981203262\n\n# Use with DBCM model:\njulia> G = MaxEntropyGraphs.Graphs.SimpleDiGraph(rhesus_macaques());\n\njulia> model = DBCM(G);\n\njulia> model_fun = θ -> L_DBCM_reduced(θ, model.dᵣ_out, model.dᵣ_in, model.f, model.dᵣ_out_nz, model.dᵣ_in_nz, model.status[:d_unique]);\n\njulia> model_fun(ones(size(model.θᵣ)))\n-252.4627226503138\n\n\n\n\n\nL_DBCM_reduced(m::DBCM)\n\nReturn the log-likelihood of the DBCM model m based on the computed maximum likelihood parameters.\n\nExamples\n\n# Use with DBCM model:\njulia> G = MaxEntropyGraphs.Graphs.SimpleDiGraph(rhesus_macaques());\n\njulia> model = DBCM(G);\n\njulia> solve_model!(model);\n\njulia> L_DBCM_reduced(model)\n-120.15942408828172\n\nSee also L_DBCM_reduced(::Vector, ::Vector, ::Vector, ::Vector, ::Vector, ::Vector)\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.∇L_DBCM_reduced!","page":"API","title":"MaxEntropyGraphs.∇L_DBCM_reduced!","text":"∇L_DBCM_reduced!(∇L::AbstractVector, θ::AbstractVector, k_out::AbstractVector, k_in::AbstractVector, F::AbstractVector, nz_out::Vector, nz_in::Vector, x::AbstractVector, y::AbstractVector,n::Int)\n\nCompute the gradient of the log-likelihood of the reduced DBCM model using the exponential formulation in order to maintain convexity.\n\nFor the optimisation, this function will be used togenerate an anonymous function associated with a specific model. The function  will update pre-allocated vectors (∇L,x and y) for speed. The gradient is non-allocating.\n\nArguments\n\n∇L: the gradient of the log-likelihood of the reduced model\nθ: the maximum likelihood parameters of the model ([α; β])\nk_out: the reduced outdegree sequence\nk_in: the reduced indegree sequence\nF: the frequency of each pair in the degree sequence\nnz_out: the indices of non-zero elements in the reduced outdegree sequence\nnz_in: the indices of non-zero elements in the reduced indegree sequence\nx: the exponentiated maximum likelihood parameters of the model ( xᵢ = exp(-αᵢ) )\ny: the exponentiated maximum likelihood parameters of the model ( yᵢ = exp(-βᵢ) )\nn: the number of nodes in the reduced model\n\nExamples\n\n# Explicit use with DBCM model:\njulia> G = MaxEntropyGraphs.Graphs.SimpleDiGraph(rhesus_macaques());\n\njulia> model = DBCM(G);\n\njulia> ∇L = zeros(Real, length(model.θᵣ));\n\njulia> x  = zeros(Real, length(model.xᵣ));\n\njulia> y  = zeros(Real, length(model.yᵣ));\n\njulia> ∇model_fun! = θ -> ∇L_DBCM_reduced!(∇L, θ, model.dᵣ_out, model.dᵣ_in, model.f, model.dᵣ_out_nz, model.dᵣ_in_nz, x, y, model.status[:d_unique]);\n\njulia> ∇model_fun!(model.θᵣ);\n\n\n# Use within optimisation.jl framework:\njulia> fun = (θ,p) -> -L_DBCM_reduced(θ, model.dᵣ_out, model.dᵣ_in, model.f, model.dᵣ_out_nz, model.dᵣ_in_nz, model.status[:d_unique]);\n\njulia> x  = zeros(Real, length(model.xᵣ)); # initialise  buffer\n\njulia> y  = zeros(Real, length(model.yᵣ));#  initialise  buffer\n\njulia> ∇fun! = (∇L, θ, p) -> ∇L_DBCM_reduced!(∇L, θ, model.dᵣ_out, model.dᵣ_in, model.f, model.dᵣ_out_nz, model.dᵣ_in_nz, x, y, model.status[:d_unique]);\n\njulia> θ₀ = initial_guess(model); # initial condition\n\njulia> foo = MaxEntropyGraphs.Optimization.OptimizationFunction(fun, grad=∇fun!); # define target function \n\njulia> prob  = MaxEntropyGraphs.Optimization.OptimizationProblem(foo, θ₀); # define the optimisation problem\n\njulia> method = MaxEntropyGraphs.OptimizationOptimJL.LBFGS(); # set the optimisation method\n\njulia> MaxEntropyGraphs.Optimization.solve(prob, method); # solve it\n\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.∇L_DBCM_reduced_minus!","page":"API","title":"MaxEntropyGraphs.∇L_DBCM_reduced_minus!","text":"∇L_DBCM_reduced_minus!(args...)\n\nCompute minus the gradient of the log-likelihood of the reduced DBCM model using the exponential formulation in order to maintain convexity. Used for optimisation in a non-allocating manner.\n\nSee also ∇L_DBCM_reduced!\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.DBCM_reduced_iter!","page":"API","title":"MaxEntropyGraphs.DBCM_reduced_iter!","text":"DBCM_reduced_iter!(θ::AbstractVector, k_out::AbstractVector, k_in::AbstractVector, F::AbstractVector, nz_out::Vector, nz_in::Vector,x::AbstractVector, y::AbstractVector, G::AbstractVector, H::AbstractVector, n::Int)\n\nComputer the next fixed-point iteration for the DBCM model using the exponential formulation in order to maintain convexity. The function is non-allocating and will update pre-allocated vectors (θ, x, y and G) for speed.\n\nArguments\n\nθ: the maximum likelihood parameters of the model ([α; β])\nk_out: the reduced outdegree sequence\nk_in: the reduced indegree sequence\nF: the frequency of each pair in the degree sequence\nnz_out: the indices of non-zero elements in the reduced outdegree sequence\nnz_in: the indices of non-zero elements in the reduced indegree sequence\nx: the exponentiated maximum likelihood parameters of the model ( xᵢ = exp(-αᵢ) )\ny: the exponentiated maximum likelihood parameters of the model ( yᵢ = exp(-βᵢ) )\nG: buffer for computations\nn: the number of nodes in the reduced model\n\nExamples\n\n# Use with DBCM model:\njulia> G = MaxEntropyGraphs.Graphs.SimpleDiGraph(rhesus_macaques());\n\njulia> model = DBCM(G);\n\njulia> G = zeros(eltype(model.θᵣ), length(model.θᵣ));\n\njulia> H = zeros(eltype(model.θᵣ), length(model.yᵣ));\n\njulia> x = zeros(eltype(model.θᵣ), length(model.xᵣ));\n\njulia> y = zeros(eltype(model.θᵣ), length(model.yᵣ));\n\njulia> DBCM_FP! = θ -> DBCM_reduced_iter!(θ, model.dᵣ_out, model.dᵣ_in, model.f, model.dᵣ_out_nz, model.dᵣ_in_nz, x, y, G, model.status[:d_unique]);\n\njulia> DBCM_FP!(model.θᵣ);\n\n\n\n\n\n\n","category":"function"},{"location":"API/#MaxEntropyGraphs.set_xᵣ!-Tuple{DBCM}","page":"API","title":"MaxEntropyGraphs.set_xᵣ!","text":"set_xᵣ!(m::DBCM)\n\nSet the value of xᵣ to exp(-αᵣ) for the DBCM model m\n\n\n\n\n\n","category":"method"},{"location":"API/#MaxEntropyGraphs.set_yᵣ!-Tuple{DBCM}","page":"API","title":"MaxEntropyGraphs.set_yᵣ!","text":"set_yᵣ!(m::DBCM)\n\nSet the value of yᵣ to exp(-βᵣ) for the DBCM model m\n\n\n\n\n\n","category":"method"},{"location":"API/#MaxEntropyGraphs.Ĝ-Tuple{DBCM}","page":"API","title":"MaxEntropyGraphs.Ĝ","text":"Ĝ(m::DBCM)\n\nCompute the expected adjacency matrix for the DBCM model m\n\n\n\n\n\n","category":"method"},{"location":"API/#MaxEntropyGraphs.set_Ĝ!-Tuple{DBCM}","page":"API","title":"MaxEntropyGraphs.set_Ĝ!","text":"set_Ĝ!(m::DBCM)\n\nSet the expected adjacency matrix for the DBCM model m\n\n\n\n\n\n","category":"method"},{"location":"API/#MaxEntropyGraphs.σˣ-Tuple{DBCM}","page":"API","title":"MaxEntropyGraphs.σˣ","text":"σˣ(m::DBCM{T,N}) where {T,N}\n\nCompute the standard deviation for the elements of the adjacency matrix for the DBCM model m.\n\nNote: read as \"sigma star\"\n\n\n\n\n\n","category":"method"},{"location":"API/#MaxEntropyGraphs.set_σ!-Tuple{DBCM}","page":"API","title":"MaxEntropyGraphs.set_σ!","text":"set_σ!(m::DBCM)\n\nSet the standard deviation for the elements of the adjacency matrix for the DBCM model m\n\n\n\n\n\n","category":"method"},{"location":"API/#Base.precision-Tuple{DBCM}","page":"API","title":"Base.precision","text":"precision(m::DBCM)\n\nDetermine the compute precision of the UBCM model m.\n\nExamples\n\njulia> model = DBCM(MaxEntropyGraphs.Graphs.SimpleDiGraph(rhesus_macaques()));\n\njulia> MaxEntropyGraphs.precision(model)\nFloat64\n\njulia> model = DBCM(MaxEntropyGraphs.Graphs.SimpleDiGraph(rhesus_macaques()), precision=Float32);\n\njulia> MaxEntropyGraphs.precision(model)\nFloat32\n\n\n\n\n\n","category":"method"},{"location":"API/#MaxEntropyGraphs.A-Tuple{DBCM, Int64, Int64}","page":"API","title":"MaxEntropyGraphs.A","text":"A(m::DBCM,i::Int,j::Int)\n\nReturn the expected value of the adjacency matrix for the DBCM model m at the node pair (i,j).\n\n❗ For perfomance reasons, the function does not check:\n\nif the node pair is valid.\nif the parameters of the model have been computed.\n\n\n\n\n\n","category":"method"},{"location":"API/#MaxEntropyGraphs.f_DBCM-Tuple{DBCM}","page":"API","title":"MaxEntropyGraphs.f_DBCM","text":"f_DBCM(x::T)\n\nHelper function for the DBCM model to compute the expected value of the adjacency matrix. The function computes the expression x / (1 + x). As an argument you need to pass the product of the maximum likelihood parameters xᵣ[i] * yᵣ[j] from a DBCM model.\n\n\n\n\n\n","category":"method"},{"location":"API/#MaxEntropyGraphs.σₓ-Tuple{DBCM, Function}","page":"API","title":"MaxEntropyGraphs.σₓ","text":"σₓ(m::DBCM, X::function)\n\nCompute the standard deviation of metric X for the DBCM model m. \n\nThis requires that both the expected values (m.Ĝ) and standard deviations (m.σ) are computed for m.\n\n\n\n\n\n","category":"method"},{"location":"metrics/#Overview","page":"Overview","title":"Overview","text":"","category":"section"},{"location":"metrics/","page":"Overview","title":"Overview","text":"Metrics are a crucial part of network analysis. They provide a way to quantify and understand the structure and behavior of a network. In the context of graph theory, metrics can be used to analyze various properties of a network, such as its connectivity, centrality, community structure and the presence of motifs. ","category":"page"},{"location":"metrics/","page":"Overview","title":"Overview","text":"Within the package, there are two main approaches to compute metrics in network analysis: analytical and simulation. ","category":"page"},{"location":"metrics/#Analytical","page":"Overview","title":"Analytical","text":"","category":"section"},{"location":"metrics/","page":"Overview","title":"Overview","text":"The analytical approach involves using mathematical methods to compute the expected value and the standard deviation of any metric that is based on the adjacency matrix. This approach allows us to compute z-scores and assess which topological properties are consistent with their randomized value within a statistical error, and which deviate significantly from the null model expectation. ","category":"page"},{"location":"metrics/","page":"Overview","title":"Overview","text":"The analytical method can be computationally expensive for large graphs due to the need for:","category":"page"},{"location":"metrics/","page":"Overview","title":"Overview","text":"the complete adjacency matrix\nthe gradient of the metric with respect to the adjacency matrix. ","category":"page"},{"location":"metrics/","page":"Overview","title":"Overview","text":"However, it provides a highly reliable estimate for the variance of the metric.  For more details, see the Analytical section.","category":"page"},{"location":"metrics/#Simulation","page":"Overview","title":"Simulation","text":"","category":"section"},{"location":"metrics/","page":"Overview","title":"Overview","text":"The simulation approach involves generating a large number of random graphs from the ensemble and computing the value of the metric(s) for each graph. This method can be more efficient for large graphs where the analytical method becomes computationally expensive. For more details, see the Simulation section.","category":"page"},{"location":"metrics/#Examples","page":"Overview","title":"Examples","text":"","category":"section"},{"location":"metrics/","page":"Overview","title":"Overview","text":"The same examples are provided for both approaches.","category":"page"},{"location":"derivedquantities/#Derived-Quantities","page":"Derived Quantities","title":"Derived Quantities","text":"","category":"section"},{"location":"GPU/#GPU","page":"GPU acceleration","title":"GPU","text":"","category":"section"},{"location":"GPU/","page":"GPU acceleration","title":"GPU acceleration","text":"Most methods can be translated to GPU computation directly thanks to the CUDA.jl environment.","category":"page"},{"location":"#MaxEntropyGraphs.jl","page":"Home","title":"MaxEntropyGraphs.jl","text":"","category":"section"},{"location":"#Overview","page":"Home","title":"Overview","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The goal of the MaxEntropyGraphs.jl package is to group the various maximum-entropy null models for network randomization and make them available to the Julia community in a single package. This work was in part inspired by the Maximum Entropy Hub, but unlike the latter, this package works in an integrated way with the exisiting Julia ecosystem for handling graphs, optimization tools and numerical solvers and groups all models in a single framework.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The package provides the following functionalities:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Computing the likelihood maximizing parameters for a broad set of network models (cf. Models section of the documentation).\nSampling of networks from a network ensemble once the parameters have been computed.\nAnalytically computing ensemble averages and their standard deviations (for a subset of models).\nRunning motif based analysis (for a subset of models).\nBipartite network projections with statistical significance analysis (for a subset of models).","category":"page"},{"location":"","page":"Home","title":"Home","text":"Each network models can be solved in different ways, with a fixed-point method typically being the fastest and a Newton-based method being the slowest. Depending on the complexity of the network model, some solvers might not always converge.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Common usage for each model is given in the Models section. For additional use cases, check the specific model page or the API reference.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Note: in allignment with the underlying theoretical framework, the graphs in the ensemble all have exactly the same number of nodes as the original network.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Assuming that you already have Julia correctly installed, installation is straightforward.  It suffices to import MaxEntropyGraphs.jl in the standard way:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(\"MaxEntropyGraphs\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"or enter the Pkg mode by hitting ], and then run the following command:","category":"page"},{"location":"","page":"Home","title":"Home","text":"pkg> add MaxEntropyGraphs","category":"page"},{"location":"#The-maximum-entropy-principle-for-networks","page":"Home","title":"The maximum entropy principle for networks","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The maximum entropy principle is a general principle in statistical mechanics that states that, given a set of constraints on a system, the probability distribution that maximizes the entropy subject to those constraints is the one that should be used to describe the system. The maximum entropy principle provides a way of constructing null models that are as unbiased or as uncertain as possible, subject to the available information, and that can be used to make statistical inferences about the underlying processes that generate the observed networks.","category":"page"},{"location":"","page":"Home","title":"Home","text":"When applied to networks, we can use this principle for the construction of an ensemble of random graphs with given constraints. This in turn allows different applications such as the detection of statistically significant structural patterns, the reconstruction of networks from partial empirical information and the sampling of graphs with specified topological properties.  ","category":"page"},{"location":"","page":"Home","title":"Home","text":"The idea is to specify a set of constraints that capture some of the structural features of the network, such as the degree sequence, the clustering coefficient, or the degree-degree correlations, and then to generate random networks that satisfy those constraints while being as unbiased or as uncertain as possible with respect to other structural features. The resulting null models can be used to test whether the observed structural features of a real-world network are statistically significant or whether they can be explained by chance alone.  The principle and its applications are explained in detail in [1]. Mathematically speaking, we want to maximize the Shannon entropy S for the canonical ensemble mathcalG of graphs G:","category":"page"},{"location":"","page":"Home","title":"Home","text":"mathcalS = - sum_G in mathcalG P(G) ln P(G) text with  sum_G in mathcalG P(G) = 1","category":"page"},{"location":"","page":"Home","title":"Home","text":"under a given set of constraints ","category":"page"},{"location":"","page":"Home","title":"Home","text":"C(G)","category":"page"},{"location":"","page":"Home","title":"Home","text":"We thus consider an ensemble of graphs mathcalG constrained by C(G), where C(G) is based on an observed network G^* with its adjacency matrix A^*.  The constrainst are imposed on average (canonical ensemble), i.e. langle C rangle = C^*, which in terms of the probability of the ensemble leads to the following:","category":"page"},{"location":"","page":"Home","title":"Home","text":"langle C rangle = sum_G in mathcalG C(G) P(G) = C^*","category":"page"},{"location":"","page":"Home","title":"Home","text":"This optimisation problem can solved by introducing a set of Langrange multipliers Theta with the same size as the number of constraints, leading to:","category":"page"},{"location":"","page":"Home","title":"Home","text":"P(G  Theta) = frace^-H(GTheta)Z(Theta)","category":"page"},{"location":"","page":"Home","title":"Home","text":"where ","category":"page"},{"location":"","page":"Home","title":"Home","text":"H(GTheta) = Theta    cdot C(G)","category":"page"},{"location":"","page":"Home","title":"Home","text":"is the graph Hamiltonian and","category":"page"},{"location":"","page":"Home","title":"Home","text":"Z(Theta) = sum_G in mathcalG e^-H(GTheta)","category":"page"},{"location":"","page":"Home","title":"Home","text":"is the partition function. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"For a given choice of the constraints C^*, the maximum-entropy graph ensemble representing the observed network G^* is obtained by  maximising the log-likelihood mathcalL defined as","category":"page"},{"location":"","page":"Home","title":"Home","text":"mathcalL(Theta) equiv ln P(G  Theta) = -H(G^*Theta) - ln Z(Theta)","category":"page"},{"location":"","page":"Home","title":"Home","text":"The canonical approach is unbiased and mathematically tractable and addintionally, it is also the most appropriate choice if one wants to account for possible errors in the data, since canonical ensembles appropriately describe systems in contact with an external reservoir (source of errors) affecting the value of the constraints","category":"page"},{"location":"","page":"Home","title":"Home","text":"Note: An adequate choice of the set of constraints can allow the probability coefficient P(G) te be written in function of the adjacency matrix, so that a probability coefficient P(A) can be assigned to every adjacency matrix in the ensemble. In that case, vecC(G) can also be written in function of the adjacency matrix vecC(A). ","category":"page"},{"location":"#Citing-MaxEntropyGraphs","page":"Home","title":"Citing MaxEntropyGraphs","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"When using this package for your scientific research please consider citing:","category":"page"},{"location":"","page":"Home","title":"Home","text":"@software{bart_de_clerck_2023_8314610,\n  author       = {Bart De Clerck},\n  title        = {B4rtDC/MaxEntropyGraphs.jl: v0.3.2},\n  month        = sep,\n  year         = 2023,\n  publisher    = {Zenodo},\n  version      = {v0.3.2},\n  doi          = {10.5281/zenodo.8314610},\n  url          = {https://doi.org/10.5281/zenodo.8314610}\n}","category":"page"},{"location":"","page":"Home","title":"Home","text":"References","category":"page"},{"location":"","page":"Home","title":"Home","text":"<ul>\n<li>\n<a id=\"1\">[1]</a> \nSquartini, Tiziano and Garlaschelli, Diego. <!--  author(s) --> \n<em>\"Maximum-Entropy Networks: Pattern Detection, Network Reconstruction and Graph Combinatorics\"</em> <!--  title --> \nSpringer-Verlag GmbH; 1st ed. 2017 edition (25 Dec. 2017). <!--  publisher(s) --> \n<a href=\"https://link.springer.com/book/10.1007/978-3-319-69438-2\">https://link.springer.com/book/10.1007/978-3-319-69438-2</a>\n</li>\n</ul>","category":"page"}]
}
